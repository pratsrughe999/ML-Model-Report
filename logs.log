2024-10-02 11:34:47,503:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-02 11:34:47,503:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-02 11:34:47,503:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-02 11:34:47,503:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-02 11:39:17,968:INFO:PyCaret RegressionExperiment
2024-10-02 11:39:17,969:INFO:Logging name: reg-default-name
2024-10-02 11:39:17,969:INFO:ML Usecase: MLUsecase.REGRESSION
2024-10-02 11:39:17,969:INFO:version 3.3.2
2024-10-02 11:39:17,969:INFO:Initializing setup()
2024-10-02 11:39:17,969:INFO:self.USI: 8d2c
2024-10-02 11:39:17,969:INFO:self._variable_keys: {'log_plots_param', 'exp_id', 'seed', 'transform_target_param', '_ml_usecase', 'USI', 'logging_param', 'html_param', 'target_param', 'X_test', 'X', 'fold_generator', 'fold_groups_param', 'n_jobs_param', 'y_test', 'data', 'y', 'X_train', 'exp_name_log', 'y_train', 'memory', 'gpu_n_jobs_param', '_available_plots', 'gpu_param', 'fold_shuffle_param', 'idx', 'pipeline'}
2024-10-02 11:39:17,969:INFO:Checking environment
2024-10-02 11:39:17,969:INFO:python_version: 3.10.9
2024-10-02 11:39:17,969:INFO:python_build: ('v3.10.9:1dd9be6584', 'Dec  6 2022 14:37:36')
2024-10-02 11:39:17,969:INFO:machine: arm64
2024-10-02 11:39:18,007:INFO:platform: macOS-13.5.1-arm64-arm-64bit
2024-10-02 11:39:18,008:INFO:Memory: svmem(total=8589934592, available=1332789248, percent=84.5, used=2858565632, free=37289984, active=1302675456, inactive=1290797056, wired=1555890176)
2024-10-02 11:39:18,008:INFO:Physical Core: 8
2024-10-02 11:39:18,008:INFO:Logical Core: 8
2024-10-02 11:39:18,008:INFO:Checking libraries
2024-10-02 11:39:18,008:INFO:System:
2024-10-02 11:39:18,008:INFO:    python: 3.10.9 (v3.10.9:1dd9be6584, Dec  6 2022, 14:37:36) [Clang 13.0.0 (clang-1300.0.29.30)]
2024-10-02 11:39:18,008:INFO:executable: /Users/pratek/test1/Report/.venv/bin/python
2024-10-02 11:39:18,008:INFO:   machine: macOS-13.5.1-arm64-arm-64bit
2024-10-02 11:39:18,008:INFO:PyCaret required dependencies:
2024-10-02 11:41:59,904:INFO:PyCaret RegressionExperiment
2024-10-02 11:41:59,904:INFO:Logging name: reg-default-name
2024-10-02 11:41:59,904:INFO:ML Usecase: MLUsecase.REGRESSION
2024-10-02 11:41:59,905:INFO:version 3.3.2
2024-10-02 11:41:59,905:INFO:Initializing setup()
2024-10-02 11:41:59,905:INFO:self.USI: edb5
2024-10-02 11:41:59,905:INFO:self._variable_keys: {'log_plots_param', 'exp_id', 'seed', 'transform_target_param', '_ml_usecase', 'USI', 'logging_param', 'html_param', 'target_param', 'X_test', 'X', 'fold_generator', 'fold_groups_param', 'n_jobs_param', 'y_test', 'data', 'y', 'X_train', 'exp_name_log', 'y_train', 'memory', 'gpu_n_jobs_param', '_available_plots', 'gpu_param', 'fold_shuffle_param', 'idx', 'pipeline'}
2024-10-02 11:41:59,905:INFO:Checking environment
2024-10-02 11:41:59,905:INFO:python_version: 3.10.9
2024-10-02 11:41:59,905:INFO:python_build: ('v3.10.9:1dd9be6584', 'Dec  6 2022 14:37:36')
2024-10-02 11:41:59,905:INFO:machine: arm64
2024-10-02 11:41:59,905:INFO:platform: macOS-13.5.1-arm64-arm-64bit
2024-10-02 11:41:59,905:INFO:Memory: svmem(total=8589934592, available=1507999744, percent=82.4, used=3011756032, free=69287936, active=1461043200, inactive=1432092672, wired=1550712832)
2024-10-02 11:41:59,905:INFO:Physical Core: 8
2024-10-02 11:41:59,905:INFO:Logical Core: 8
2024-10-02 11:41:59,905:INFO:Checking libraries
2024-10-02 11:41:59,906:INFO:System:
2024-10-02 11:41:59,906:INFO:    python: 3.10.9 (v3.10.9:1dd9be6584, Dec  6 2022, 14:37:36) [Clang 13.0.0 (clang-1300.0.29.30)]
2024-10-02 11:41:59,906:INFO:executable: /Users/pratek/test1/Report/.venv/bin/python
2024-10-02 11:41:59,906:INFO:   machine: macOS-13.5.1-arm64-arm-64bit
2024-10-02 11:41:59,906:INFO:PyCaret required dependencies:
2024-10-02 11:43:02,680:INFO:PyCaret ClassificationExperiment
2024-10-02 11:43:02,681:INFO:Logging name: clf-default-name
2024-10-02 11:43:02,681:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-10-02 11:43:02,681:INFO:version 3.3.2
2024-10-02 11:43:02,681:INFO:Initializing setup()
2024-10-02 11:43:02,681:INFO:self.USI: fcaf
2024-10-02 11:43:02,681:INFO:self._variable_keys: {'log_plots_param', 'exp_id', 'seed', '_ml_usecase', 'USI', 'logging_param', 'html_param', 'target_param', 'X_test', 'X', 'fold_generator', 'fold_groups_param', 'is_multiclass', 'fix_imbalance', 'n_jobs_param', 'y_test', 'data', 'y', 'X_train', 'exp_name_log', 'y_train', 'memory', 'gpu_n_jobs_param', '_available_plots', 'gpu_param', 'fold_shuffle_param', 'idx', 'pipeline'}
2024-10-02 11:43:02,681:INFO:Checking environment
2024-10-02 11:43:02,681:INFO:python_version: 3.10.9
2024-10-02 11:43:02,681:INFO:python_build: ('v3.10.9:1dd9be6584', 'Dec  6 2022 14:37:36')
2024-10-02 11:43:02,682:INFO:machine: arm64
2024-10-02 11:43:02,682:INFO:platform: macOS-13.5.1-arm64-arm-64bit
2024-10-02 11:43:02,682:INFO:Memory: svmem(total=8589934592, available=1436008448, percent=83.3, used=2936389632, free=65159168, active=1386446848, inactive=1366179840, wired=1549942784)
2024-10-02 11:43:02,682:INFO:Physical Core: 8
2024-10-02 11:43:02,682:INFO:Logical Core: 8
2024-10-02 11:43:02,682:INFO:Checking libraries
2024-10-02 11:43:02,682:INFO:System:
2024-10-02 11:43:02,682:INFO:    python: 3.10.9 (v3.10.9:1dd9be6584, Dec  6 2022, 14:37:36) [Clang 13.0.0 (clang-1300.0.29.30)]
2024-10-02 11:43:02,682:INFO:executable: /Users/pratek/test1/Report/.venv/bin/python
2024-10-02 11:43:02,682:INFO:   machine: macOS-13.5.1-arm64-arm-64bit
2024-10-02 11:43:02,682:INFO:PyCaret required dependencies:
2024-10-02 11:43:27,066:INFO:PyCaret ClassificationExperiment
2024-10-02 11:43:27,066:INFO:Logging name: clf-default-name
2024-10-02 11:43:27,067:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-10-02 11:43:27,067:INFO:version 3.3.2
2024-10-02 11:43:27,067:INFO:Initializing setup()
2024-10-02 11:43:27,067:INFO:self.USI: f754
2024-10-02 11:43:27,067:INFO:self._variable_keys: {'log_plots_param', 'exp_id', 'seed', '_ml_usecase', 'USI', 'logging_param', 'html_param', 'target_param', 'X_test', 'X', 'fold_generator', 'fold_groups_param', 'is_multiclass', 'fix_imbalance', 'n_jobs_param', 'y_test', 'data', 'y', 'X_train', 'exp_name_log', 'y_train', 'memory', 'gpu_n_jobs_param', '_available_plots', 'gpu_param', 'fold_shuffle_param', 'idx', 'pipeline'}
2024-10-02 11:43:27,067:INFO:Checking environment
2024-10-02 11:43:27,067:INFO:python_version: 3.10.9
2024-10-02 11:43:27,067:INFO:python_build: ('v3.10.9:1dd9be6584', 'Dec  6 2022 14:37:36')
2024-10-02 11:43:27,067:INFO:machine: arm64
2024-10-02 11:43:27,068:INFO:platform: macOS-13.5.1-arm64-arm-64bit
2024-10-02 11:43:27,068:INFO:Memory: svmem(total=8589934592, available=1391296512, percent=83.8, used=2943352832, free=35913728, active=1377419264, inactive=1347059712, wired=1565933568)
2024-10-02 11:43:27,068:INFO:Physical Core: 8
2024-10-02 11:43:27,068:INFO:Logical Core: 8
2024-10-02 11:43:27,068:INFO:Checking libraries
2024-10-02 11:43:27,068:INFO:System:
2024-10-02 11:43:27,068:INFO:    python: 3.10.9 (v3.10.9:1dd9be6584, Dec  6 2022, 14:37:36) [Clang 13.0.0 (clang-1300.0.29.30)]
2024-10-02 11:43:27,068:INFO:executable: /Users/pratek/test1/Report/.venv/bin/python
2024-10-02 11:43:27,068:INFO:   machine: macOS-13.5.1-arm64-arm-64bit
2024-10-02 11:43:27,068:INFO:PyCaret required dependencies:
2024-10-02 11:46:20,066:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-02 11:46:20,067:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-02 11:46:20,067:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-02 11:46:20,067:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-10-02 11:46:23,630:INFO:PyCaret ClassificationExperiment
2024-10-02 11:46:23,630:INFO:Logging name: clf-default-name
2024-10-02 11:46:23,630:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-10-02 11:46:23,631:INFO:version 3.3.2
2024-10-02 11:46:23,631:INFO:Initializing setup()
2024-10-02 11:46:23,631:INFO:self.USI: 22c9
2024-10-02 11:46:23,631:INFO:self._variable_keys: {'y_train', 'logging_param', 'fold_shuffle_param', '_ml_usecase', 'n_jobs_param', 'fold_generator', 'idx', 'data', 'pipeline', 'exp_name_log', 'X', 'gpu_param', 'html_param', 'gpu_n_jobs_param', 'target_param', 'y_test', 'fix_imbalance', 'X_test', 'fold_groups_param', 'log_plots_param', 'exp_id', 'y', 'X_train', '_available_plots', 'USI', 'memory', 'is_multiclass', 'seed'}
2024-10-02 11:46:23,631:INFO:Checking environment
2024-10-02 11:46:23,631:INFO:python_version: 3.10.9
2024-10-02 11:46:23,631:INFO:python_build: ('v3.10.9:1dd9be6584', 'Dec  6 2022 14:37:36')
2024-10-02 11:46:23,631:INFO:machine: arm64
2024-10-02 11:46:23,667:INFO:platform: macOS-13.5.1-arm64-arm-64bit
2024-10-02 11:46:23,668:INFO:Memory: svmem(total=8589934592, available=1330118656, percent=84.5, used=2862366720, free=55361536, active=1284063232, inactive=1215381504, wired=1578303488)
2024-10-02 11:46:23,668:INFO:Physical Core: 8
2024-10-02 11:46:23,668:INFO:Logical Core: 8
2024-10-02 11:46:23,668:INFO:Checking libraries
2024-10-02 11:46:23,668:INFO:System:
2024-10-02 11:46:23,668:INFO:    python: 3.10.9 (v3.10.9:1dd9be6584, Dec  6 2022, 14:37:36) [Clang 13.0.0 (clang-1300.0.29.30)]
2024-10-02 11:46:23,668:INFO:executable: /Users/pratek/test1/Report/.venv/bin/python
2024-10-02 11:46:23,668:INFO:   machine: macOS-13.5.1-arm64-arm-64bit
2024-10-02 11:46:23,668:INFO:PyCaret required dependencies:
2024-10-02 11:46:24,091:INFO:                 pip: 24.2
2024-10-02 11:46:24,091:INFO:          setuptools: 68.2.0
2024-10-02 11:46:24,091:INFO:             pycaret: 3.3.2
2024-10-02 11:46:24,091:INFO:             IPython: 8.27.0
2024-10-02 11:46:24,091:INFO:          ipywidgets: 8.1.5
2024-10-02 11:46:24,091:INFO:                tqdm: 4.66.5
2024-10-02 11:46:24,091:INFO:               numpy: 1.26.4
2024-10-02 11:46:24,091:INFO:              pandas: 2.1.4
2024-10-02 11:46:24,091:INFO:              jinja2: 3.1.4
2024-10-02 11:46:24,091:INFO:               scipy: 1.11.4
2024-10-02 11:46:24,091:INFO:              joblib: 1.3.2
2024-10-02 11:46:24,091:INFO:             sklearn: 1.4.2
2024-10-02 11:46:24,091:INFO:                pyod: 2.0.2
2024-10-02 11:46:24,091:INFO:            imblearn: 0.12.3
2024-10-02 11:46:24,091:INFO:   category_encoders: 2.6.4
2024-10-02 11:46:24,091:INFO:            lightgbm: 4.5.0
2024-10-02 11:46:24,091:INFO:               numba: 0.60.0
2024-10-02 11:46:24,091:INFO:            requests: 2.32.3
2024-10-02 11:46:24,091:INFO:          matplotlib: 3.7.5
2024-10-02 11:46:24,091:INFO:          scikitplot: 0.3.7
2024-10-02 11:46:24,091:INFO:         yellowbrick: 1.5
2024-10-02 11:46:24,092:INFO:              plotly: 5.24.1
2024-10-02 11:46:24,092:INFO:    plotly-resampler: Not installed
2024-10-02 11:46:24,092:INFO:             kaleido: 0.2.1
2024-10-02 11:46:24,092:INFO:           schemdraw: 0.15
2024-10-02 11:46:24,092:INFO:         statsmodels: 0.14.3
2024-10-02 11:46:24,092:INFO:              sktime: 0.26.0
2024-10-02 11:46:24,092:INFO:               tbats: 1.1.3
2024-10-02 11:46:24,092:INFO:            pmdarima: 2.0.4
2024-10-02 11:46:24,092:INFO:              psutil: 6.0.0
2024-10-02 11:46:24,092:INFO:          markupsafe: 2.1.5
2024-10-02 11:46:24,092:INFO:             pickle5: Not installed
2024-10-02 11:46:24,092:INFO:         cloudpickle: 3.0.0
2024-10-02 11:46:24,092:INFO:         deprecation: 2.1.0
2024-10-02 11:46:24,092:INFO:              xxhash: 3.5.0
2024-10-02 11:46:24,092:INFO:           wurlitzer: 3.1.1
2024-10-02 11:46:24,092:INFO:PyCaret optional dependencies:
2024-10-02 11:46:24,100:INFO:                shap: Not installed
2024-10-02 11:46:24,100:INFO:           interpret: Not installed
2024-10-02 11:46:24,100:INFO:                umap: Not installed
2024-10-02 11:46:24,100:INFO:     ydata_profiling: 4.10.0
2024-10-02 11:46:24,100:INFO:  explainerdashboard: Not installed
2024-10-02 11:46:24,100:INFO:             autoviz: Not installed
2024-10-02 11:46:24,100:INFO:           fairlearn: Not installed
2024-10-02 11:46:24,100:INFO:          deepchecks: Not installed
2024-10-02 11:46:24,100:INFO:             xgboost: Not installed
2024-10-02 11:46:24,100:INFO:            catboost: Not installed
2024-10-02 11:46:24,100:INFO:              kmodes: Not installed
2024-10-02 11:46:24,100:INFO:             mlxtend: Not installed
2024-10-02 11:46:24,100:INFO:       statsforecast: Not installed
2024-10-02 11:46:24,100:INFO:        tune_sklearn: Not installed
2024-10-02 11:46:24,100:INFO:                 ray: Not installed
2024-10-02 11:46:24,100:INFO:            hyperopt: Not installed
2024-10-02 11:46:24,100:INFO:              optuna: Not installed
2024-10-02 11:46:24,100:INFO:               skopt: Not installed
2024-10-02 11:46:24,100:INFO:              mlflow: Not installed
2024-10-02 11:46:24,100:INFO:              gradio: Not installed
2024-10-02 11:46:24,100:INFO:             fastapi: Not installed
2024-10-02 11:46:24,100:INFO:             uvicorn: Not installed
2024-10-02 11:46:24,100:INFO:              m2cgen: Not installed
2024-10-02 11:46:24,100:INFO:           evidently: Not installed
2024-10-02 11:46:24,100:INFO:               fugue: Not installed
2024-10-02 11:46:24,100:INFO:           streamlit: 1.39.0
2024-10-02 11:46:24,100:INFO:             prophet: Not installed
2024-10-02 11:46:24,100:INFO:None
2024-10-02 11:46:24,100:INFO:Set up data.
2024-10-02 11:46:24,110:INFO:Set up folding strategy.
2024-10-02 11:46:24,111:INFO:Set up train/test split.
2024-10-02 11:46:24,115:INFO:Set up index.
2024-10-02 11:46:24,115:INFO:Assigning column types.
2024-10-02 11:46:24,117:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-10-02 11:46:24,137:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-02 11:46:24,139:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-02 11:46:24,153:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:46:24,153:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:46:24,170:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-02 11:46:24,170:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-02 11:46:24,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:46:24,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:46:24,181:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-10-02 11:46:24,198:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-02 11:46:24,208:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:46:24,208:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:46:24,225:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-02 11:46:24,236:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:46:24,236:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:46:24,236:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-10-02 11:46:24,263:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:46:24,263:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:46:24,291:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:46:24,291:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:46:24,293:INFO:Preparing preprocessing pipeline...
2024-10-02 11:46:24,294:INFO:Set up label encoding.
2024-10-02 11:46:24,294:INFO:Set up simple imputation.
2024-10-02 11:46:24,305:INFO:Finished creating preprocessing pipeline.
2024-10-02 11:46:24,307:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/tx/71pw4d8d2l95h2ffhyf9cq340000gn/T/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sex', 'cp', 'trestbps', 'chol',
                                             'fbs', 'restecg', 'thalach',
                                             'exang', 'oldpeak', 'slope', 'ca'...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-10-02 11:46:24,307:INFO:Creating final display dataframe.
2024-10-02 11:46:24,337:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                               8565
1                        Target                                                age
2                   Target type                                         Multiclass
3                Target mapping  29: 0, 34: 1, 35: 2, 37: 3, 38: 4, 39: 5, 40: ...
4           Original data shape                                         (1025, 14)
5        Transformed data shape                                         (1025, 14)
6   Transformed train set shape                                          (717, 14)
7    Transformed test set shape                                          (308, 14)
8              Numeric features                                                 13
9                    Preprocess                                               True
10              Imputation type                                             simple
11           Numeric imputation                                               mean
12       Categorical imputation                                               mode
13               Fold Generator                                    StratifiedKFold
14                  Fold Number                                                 10
15                     CPU Jobs                                                 -1
16                      Use GPU                                              False
17               Log Experiment                                              False
18              Experiment Name                                   clf-default-name
19                          USI                                               22c9
2024-10-02 11:46:24,367:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:46:24,367:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:46:24,395:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:46:24,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:46:24,396:INFO:setup() successfully completed in 0.77s...............
2024-10-02 11:46:24,409:INFO:Initializing compare_models()
2024-10-02 11:46:24,409:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17dd4e8c0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x17dd4e8c0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-10-02 11:46:24,409:INFO:Checking exceptions
2024-10-02 11:46:24,411:INFO:Preparing display monitor
2024-10-02 11:46:24,736:INFO:Initializing Logistic Regression
2024-10-02 11:46:24,737:INFO:Total runtime is 1.7583370208740234e-05 minutes
2024-10-02 11:46:24,737:INFO:SubProcess create_model() called ==================================
2024-10-02 11:46:24,737:INFO:Initializing create_model()
2024-10-02 11:46:24,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17dd4e8c0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17207ca90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:46:24,738:INFO:Checking exceptions
2024-10-02 11:46:24,738:INFO:Importing libraries
2024-10-02 11:46:24,738:INFO:Copying training dataset
2024-10-02 11:46:24,745:INFO:Defining folds
2024-10-02 11:46:24,745:INFO:Declaring metric variables
2024-10-02 11:46:24,746:INFO:Importing untrained model
2024-10-02 11:46:24,746:INFO:Logistic Regression Imported successfully
2024-10-02 11:46:24,747:INFO:Starting cross validation
2024-10-02 11:46:24,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:46:24,766:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2024-10-02 11:46:27,213:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-10-02 11:46:27,232:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:27,235:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,237:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,237:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,238:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,238:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,238:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,256:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-10-02 11:46:27,268:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:27,269:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,270:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,270:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,271:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,272:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,272:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,288:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-10-02 11:46:27,297:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:27,298:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,299:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,300:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,301:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,301:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,302:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,316:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-10-02 11:46:27,322:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:27,322:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-10-02 11:46:27,323:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,324:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,325:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-10-02 11:46:27,326:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,327:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,328:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,329:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,331:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:27,333:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,334:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:27,335:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,336:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,336:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,337:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,337:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,337:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,339:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,340:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,340:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,341:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,341:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,363:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-10-02 11:46:27,375:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:27,377:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,379:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,380:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-10-02 11:46:27,381:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,382:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,384:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,385:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,391:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:27,393:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,395:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,397:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,398:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,400:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,402:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,654:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-10-02 11:46:27,657:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:27,658:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,658:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,659:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,659:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,660:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,660:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,665:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-10-02 11:46:27,668:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:27,668:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,669:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,669:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,670:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,670:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,670:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,674:INFO:Calculating mean and std
2024-10-02 11:46:27,675:INFO:Creating metrics dataframe
2024-10-02 11:46:27,678:INFO:Uploading results into container
2024-10-02 11:46:27,679:INFO:Uploading model into container now
2024-10-02 11:46:27,679:INFO:_master_model_container: 1
2024-10-02 11:46:27,679:INFO:_display_container: 2
2024-10-02 11:46:27,679:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8565, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-10-02 11:46:27,679:INFO:create_model() successfully completed......................................
2024-10-02 11:46:27,768:INFO:SubProcess create_model() end ==================================
2024-10-02 11:46:27,768:INFO:Creating metrics dataframe
2024-10-02 11:46:27,770:INFO:Initializing K Neighbors Classifier
2024-10-02 11:46:27,770:INFO:Total runtime is 0.05057311455408732 minutes
2024-10-02 11:46:27,770:INFO:SubProcess create_model() called ==================================
2024-10-02 11:46:27,770:INFO:Initializing create_model()
2024-10-02 11:46:27,770:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17dd4e8c0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17207ca90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:46:27,770:INFO:Checking exceptions
2024-10-02 11:46:27,770:INFO:Importing libraries
2024-10-02 11:46:27,770:INFO:Copying training dataset
2024-10-02 11:46:27,772:INFO:Defining folds
2024-10-02 11:46:27,772:INFO:Declaring metric variables
2024-10-02 11:46:27,772:INFO:Importing untrained model
2024-10-02 11:46:27,772:INFO:K Neighbors Classifier Imported successfully
2024-10-02 11:46:27,772:INFO:Starting cross validation
2024-10-02 11:46:27,773:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:46:27,774:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2024-10-02 11:46:27,818:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:27,818:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,819:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,819:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:27,819:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,820:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,820:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,820:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,820:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,821:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,821:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,821:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,821:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,822:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,823:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:27,824:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,824:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,825:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,826:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,826:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,826:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,830:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:27,830:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,831:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,832:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,832:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:27,832:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,833:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,833:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,833:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,833:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,834:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,834:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,835:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,836:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,839:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:27,840:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,841:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,841:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,842:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,842:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,843:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,851:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:27,852:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,852:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,853:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,853:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,853:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,854:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,857:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:27,858:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,858:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,859:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,859:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,860:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:27,860:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,860:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,860:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,861:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,861:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,862:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,862:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,862:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,869:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:27,873:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,874:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,874:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,875:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,876:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,876:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,880:INFO:Calculating mean and std
2024-10-02 11:46:27,880:INFO:Creating metrics dataframe
2024-10-02 11:46:27,881:INFO:Uploading results into container
2024-10-02 11:46:27,881:INFO:Uploading model into container now
2024-10-02 11:46:27,881:INFO:_master_model_container: 2
2024-10-02 11:46:27,881:INFO:_display_container: 2
2024-10-02 11:46:27,882:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-10-02 11:46:27,882:INFO:create_model() successfully completed......................................
2024-10-02 11:46:27,920:INFO:SubProcess create_model() end ==================================
2024-10-02 11:46:27,920:INFO:Creating metrics dataframe
2024-10-02 11:46:27,921:INFO:Initializing Naive Bayes
2024-10-02 11:46:27,922:INFO:Total runtime is 0.053098718325297035 minutes
2024-10-02 11:46:27,922:INFO:SubProcess create_model() called ==================================
2024-10-02 11:46:27,922:INFO:Initializing create_model()
2024-10-02 11:46:27,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17dd4e8c0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17207ca90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:46:27,922:INFO:Checking exceptions
2024-10-02 11:46:27,922:INFO:Importing libraries
2024-10-02 11:46:27,922:INFO:Copying training dataset
2024-10-02 11:46:27,923:INFO:Defining folds
2024-10-02 11:46:27,923:INFO:Declaring metric variables
2024-10-02 11:46:27,923:INFO:Importing untrained model
2024-10-02 11:46:27,923:INFO:Naive Bayes Imported successfully
2024-10-02 11:46:27,923:INFO:Starting cross validation
2024-10-02 11:46:27,924:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:46:27,925:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2024-10-02 11:46:27,938:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:27,938:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,939:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,939:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,941:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,941:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:27,941:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,942:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,942:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,943:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,943:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,943:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,944:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,944:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,947:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:27,948:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,949:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:27,949:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,949:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,949:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,950:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,950:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,950:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,951:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,951:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,951:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:27,951:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,952:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,952:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,952:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,953:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,953:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:27,953:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,953:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,954:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,954:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,954:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,954:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,955:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,955:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,955:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,956:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,957:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:27,957:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,958:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,958:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,959:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,959:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,959:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,959:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:27,960:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,960:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,961:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,961:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,962:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,962:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,963:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:27,963:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:27,964:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,964:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,964:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,964:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,964:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,965:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,965:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,965:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,965:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,966:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:27,966:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,966:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:27,976:INFO:Calculating mean and std
2024-10-02 11:46:27,976:INFO:Creating metrics dataframe
2024-10-02 11:46:27,977:INFO:Uploading results into container
2024-10-02 11:46:27,977:INFO:Uploading model into container now
2024-10-02 11:46:27,977:INFO:_master_model_container: 3
2024-10-02 11:46:27,977:INFO:_display_container: 2
2024-10-02 11:46:27,977:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-10-02 11:46:27,977:INFO:create_model() successfully completed......................................
2024-10-02 11:46:28,014:INFO:SubProcess create_model() end ==================================
2024-10-02 11:46:28,014:INFO:Creating metrics dataframe
2024-10-02 11:46:28,015:INFO:Initializing Decision Tree Classifier
2024-10-02 11:46:28,015:INFO:Total runtime is 0.05465793212254842 minutes
2024-10-02 11:46:28,015:INFO:SubProcess create_model() called ==================================
2024-10-02 11:46:28,015:INFO:Initializing create_model()
2024-10-02 11:46:28,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17dd4e8c0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17207ca90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:46:28,015:INFO:Checking exceptions
2024-10-02 11:46:28,015:INFO:Importing libraries
2024-10-02 11:46:28,015:INFO:Copying training dataset
2024-10-02 11:46:28,017:INFO:Defining folds
2024-10-02 11:46:28,017:INFO:Declaring metric variables
2024-10-02 11:46:28,017:INFO:Importing untrained model
2024-10-02 11:46:28,017:INFO:Decision Tree Classifier Imported successfully
2024-10-02 11:46:28,017:INFO:Starting cross validation
2024-10-02 11:46:28,017:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:46:28,019:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2024-10-02 11:46:28,035:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:28,035:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:28,035:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,035:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,035:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,036:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,036:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,036:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,036:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,037:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,037:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,037:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,037:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,038:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,040:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:28,040:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:28,040:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,041:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,041:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,041:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,041:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,042:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,042:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,042:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,042:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,043:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,043:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,043:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,046:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:28,048:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,049:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,049:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:28,049:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:28,049:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,049:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,050:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,050:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,050:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,050:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,050:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,050:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,051:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,051:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:28,051:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,051:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,051:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,052:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:28,052:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,052:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,053:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,053:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,053:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,053:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,053:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,054:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:28,054:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,054:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,054:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,054:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,054:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,054:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,054:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,054:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,055:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,055:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,055:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,055:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,055:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,056:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,056:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,068:INFO:Calculating mean and std
2024-10-02 11:46:28,068:INFO:Creating metrics dataframe
2024-10-02 11:46:28,069:INFO:Uploading results into container
2024-10-02 11:46:28,069:INFO:Uploading model into container now
2024-10-02 11:46:28,069:INFO:_master_model_container: 4
2024-10-02 11:46:28,069:INFO:_display_container: 2
2024-10-02 11:46:28,069:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8565, splitter='best')
2024-10-02 11:46:28,069:INFO:create_model() successfully completed......................................
2024-10-02 11:46:28,111:INFO:SubProcess create_model() end ==================================
2024-10-02 11:46:28,111:INFO:Creating metrics dataframe
2024-10-02 11:46:28,112:INFO:Initializing SVM - Linear Kernel
2024-10-02 11:46:28,112:INFO:Total runtime is 0.0562817653020223 minutes
2024-10-02 11:46:28,113:INFO:SubProcess create_model() called ==================================
2024-10-02 11:46:28,113:INFO:Initializing create_model()
2024-10-02 11:46:28,113:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17dd4e8c0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17207ca90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:46:28,113:INFO:Checking exceptions
2024-10-02 11:46:28,113:INFO:Importing libraries
2024-10-02 11:46:28,113:INFO:Copying training dataset
2024-10-02 11:46:28,114:INFO:Defining folds
2024-10-02 11:46:28,114:INFO:Declaring metric variables
2024-10-02 11:46:28,114:INFO:Importing untrained model
2024-10-02 11:46:28,115:INFO:SVM - Linear Kernel Imported successfully
2024-10-02 11:46:28,115:INFO:Starting cross validation
2024-10-02 11:46:28,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:46:28,116:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2024-10-02 11:46:28,162:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,162:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,162:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,163:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,163:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,164:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,164:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,172:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,172:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,173:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,173:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,174:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,174:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,174:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,177:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,178:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,178:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,179:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,179:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,180:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,180:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,187:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,188:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,188:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,189:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,189:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,190:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,190:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,191:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,191:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,192:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,192:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,193:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,193:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,194:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,197:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,198:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,198:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,199:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,199:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,200:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,200:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,203:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,204:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,204:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,205:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,205:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,205:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,206:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,207:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,208:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,208:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,209:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,209:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,209:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,210:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,214:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,214:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,215:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,215:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,216:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,216:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,216:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,225:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,226:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,226:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,227:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,227:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,227:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,228:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,230:INFO:Calculating mean and std
2024-10-02 11:46:28,230:INFO:Creating metrics dataframe
2024-10-02 11:46:28,231:INFO:Uploading results into container
2024-10-02 11:46:28,231:INFO:Uploading model into container now
2024-10-02 11:46:28,231:INFO:_master_model_container: 5
2024-10-02 11:46:28,231:INFO:_display_container: 2
2024-10-02 11:46:28,231:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8565, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-10-02 11:46:28,231:INFO:create_model() successfully completed......................................
2024-10-02 11:46:28,273:INFO:SubProcess create_model() end ==================================
2024-10-02 11:46:28,273:INFO:Creating metrics dataframe
2024-10-02 11:46:28,275:INFO:Initializing Ridge Classifier
2024-10-02 11:46:28,275:INFO:Total runtime is 0.058983314037323 minutes
2024-10-02 11:46:28,275:INFO:SubProcess create_model() called ==================================
2024-10-02 11:46:28,275:INFO:Initializing create_model()
2024-10-02 11:46:28,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17dd4e8c0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17207ca90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:46:28,275:INFO:Checking exceptions
2024-10-02 11:46:28,275:INFO:Importing libraries
2024-10-02 11:46:28,275:INFO:Copying training dataset
2024-10-02 11:46:28,276:INFO:Defining folds
2024-10-02 11:46:28,276:INFO:Declaring metric variables
2024-10-02 11:46:28,276:INFO:Importing untrained model
2024-10-02 11:46:28,276:INFO:Ridge Classifier Imported successfully
2024-10-02 11:46:28,276:INFO:Starting cross validation
2024-10-02 11:46:28,277:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:46:28,278:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2024-10-02 11:46:28,295:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,296:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,296:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,296:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,296:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,296:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,296:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,296:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,297:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,297:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,297:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,297:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,297:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,297:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,297:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,297:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,297:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,298:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,298:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,298:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,298:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,298:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,298:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,299:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,299:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,300:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,300:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,301:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,302:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,302:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,302:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,303:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,303:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,303:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,304:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,305:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,306:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,306:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,307:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,307:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,307:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,307:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,307:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,308:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,308:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,308:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,308:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,308:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,308:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,308:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,309:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,309:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,309:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,309:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,310:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,310:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,311:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,311:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,312:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,312:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,313:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,313:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,313:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,314:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,314:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,314:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,315:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,315:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,316:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,316:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,327:INFO:Calculating mean and std
2024-10-02 11:46:28,328:INFO:Creating metrics dataframe
2024-10-02 11:46:28,328:INFO:Uploading results into container
2024-10-02 11:46:28,328:INFO:Uploading model into container now
2024-10-02 11:46:28,329:INFO:_master_model_container: 6
2024-10-02 11:46:28,329:INFO:_display_container: 2
2024-10-02 11:46:28,329:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8565, solver='auto',
                tol=0.0001)
2024-10-02 11:46:28,329:INFO:create_model() successfully completed......................................
2024-10-02 11:46:28,364:INFO:SubProcess create_model() end ==================================
2024-10-02 11:46:28,364:INFO:Creating metrics dataframe
2024-10-02 11:46:28,365:INFO:Initializing Random Forest Classifier
2024-10-02 11:46:28,365:INFO:Total runtime is 0.06049438317616781 minutes
2024-10-02 11:46:28,365:INFO:SubProcess create_model() called ==================================
2024-10-02 11:46:28,365:INFO:Initializing create_model()
2024-10-02 11:46:28,365:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17dd4e8c0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17207ca90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:46:28,365:INFO:Checking exceptions
2024-10-02 11:46:28,365:INFO:Importing libraries
2024-10-02 11:46:28,365:INFO:Copying training dataset
2024-10-02 11:46:28,367:INFO:Defining folds
2024-10-02 11:46:28,367:INFO:Declaring metric variables
2024-10-02 11:46:28,367:INFO:Importing untrained model
2024-10-02 11:46:28,367:INFO:Random Forest Classifier Imported successfully
2024-10-02 11:46:28,367:INFO:Starting cross validation
2024-10-02 11:46:28,368:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:46:28,369:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2024-10-02 11:46:28,569:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:28,570:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,570:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,571:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,572:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,572:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,573:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,575:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:28,575:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,576:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,576:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,577:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,577:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,578:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,579:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:28,580:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,581:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,581:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,582:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,583:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,583:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:28,583:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,584:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,585:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,586:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,586:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,587:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,587:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,604:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:28,608:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,609:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:28,609:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,610:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,611:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,611:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,611:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,612:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,613:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,614:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,615:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,615:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,616:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,636:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:28,637:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,637:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,638:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,638:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,639:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,639:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,658:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:28,659:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,660:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,660:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,660:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,661:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,661:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,700:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:28,700:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,701:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,701:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:28,701:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,701:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,701:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,702:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,702:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,702:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,702:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,703:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,703:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,703:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,713:INFO:Calculating mean and std
2024-10-02 11:46:28,713:INFO:Creating metrics dataframe
2024-10-02 11:46:28,714:INFO:Uploading results into container
2024-10-02 11:46:28,714:INFO:Uploading model into container now
2024-10-02 11:46:28,714:INFO:_master_model_container: 7
2024-10-02 11:46:28,714:INFO:_display_container: 2
2024-10-02 11:46:28,714:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8565, verbose=0,
                       warm_start=False)
2024-10-02 11:46:28,714:INFO:create_model() successfully completed......................................
2024-10-02 11:46:28,749:INFO:SubProcess create_model() end ==================================
2024-10-02 11:46:28,749:INFO:Creating metrics dataframe
2024-10-02 11:46:28,751:INFO:Initializing Quadratic Discriminant Analysis
2024-10-02 11:46:28,751:INFO:Total runtime is 0.0669223149617513 minutes
2024-10-02 11:46:28,751:INFO:SubProcess create_model() called ==================================
2024-10-02 11:46:28,751:INFO:Initializing create_model()
2024-10-02 11:46:28,751:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17dd4e8c0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17207ca90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:46:28,751:INFO:Checking exceptions
2024-10-02 11:46:28,751:INFO:Importing libraries
2024-10-02 11:46:28,751:INFO:Copying training dataset
2024-10-02 11:46:28,753:INFO:Defining folds
2024-10-02 11:46:28,753:INFO:Declaring metric variables
2024-10-02 11:46:28,753:INFO:Importing untrained model
2024-10-02 11:46:28,753:INFO:Quadratic Discriminant Analysis Imported successfully
2024-10-02 11:46:28,753:INFO:Starting cross validation
2024-10-02 11:46:28,753:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:46:28,754:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2024-10-02 11:46:28,764:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-10-02 11:46:28,764:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-10-02 11:46:28,765:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-10-02 11:46:28,767:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,767:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,767:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,767:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,768:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-10-02 11:46:28,768:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-10-02 11:46:28,768:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,768:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,769:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-10-02 11:46:28,769:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,769:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,769:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,769:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,770:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-10-02 11:46:28,770:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-10-02 11:46:28,770:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,770:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,771:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-10-02 11:46:28,772:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-10-02 11:46:28,772:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-10-02 11:46:28,772:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-10-02 11:46:28,772:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-10-02 11:46:28,773:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,773:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,774:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,774:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,774:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,775:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,775:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,775:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,776:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,776:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,777:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,777:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,779:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,779:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,779:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,779:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,780:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,780:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-10-02 11:46:28,780:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,780:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-10-02 11:46:28,780:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,781:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,781:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,781:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-10-02 11:46:28,781:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-10-02 11:46:28,782:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,782:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-10-02 11:46:28,782:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-10-02 11:46:28,783:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,783:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,784:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,784:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,785:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,785:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,785:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,785:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,786:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-10-02 11:46:28,786:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-10-02 11:46:28,786:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,786:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,787:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-10-02 11:46:28,787:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-10-02 11:46:28,788:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-10-02 11:46:28,788:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,788:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,788:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-10-02 11:46:28,789:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,789:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,789:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,789:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,790:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-10-02 11:46:28,790:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,790:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,790:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,790:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,791:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-10-02 11:46:28,791:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-10-02 11:46:28,791:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,791:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,792:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,792:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-10-02 11:46:28,792:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,792:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,793:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,793:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-10-02 11:46:28,793:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,793:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-10-02 11:46:28,793:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,793:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-10-02 11:46:28,794:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,794:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,794:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,795:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,795:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,796:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,796:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,806:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: 
3 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py", line 926, in fit
    raise ValueError(
ValueError: y has only 1 sample in class 38, covariance is ill defined.

--------------------------------------------------------------------------------
1 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/base.py", line 1474, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/discriminant_analysis.py", line 926, in fit
    raise ValueError(
ValueError: y has only 1 sample in class 40, covariance is ill defined.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-10-02 11:46:28,806:INFO:Calculating mean and std
2024-10-02 11:46:28,807:INFO:Creating metrics dataframe
2024-10-02 11:46:28,807:INFO:Uploading results into container
2024-10-02 11:46:28,807:INFO:Uploading model into container now
2024-10-02 11:46:28,808:INFO:_master_model_container: 8
2024-10-02 11:46:28,808:INFO:_display_container: 2
2024-10-02 11:46:28,808:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-10-02 11:46:28,808:INFO:create_model() successfully completed......................................
2024-10-02 11:46:28,845:INFO:SubProcess create_model() end ==================================
2024-10-02 11:46:28,845:INFO:Creating metrics dataframe
2024-10-02 11:46:28,846:INFO:Initializing Ada Boost Classifier
2024-10-02 11:46:28,846:INFO:Total runtime is 0.06850593090057373 minutes
2024-10-02 11:46:28,846:INFO:SubProcess create_model() called ==================================
2024-10-02 11:46:28,846:INFO:Initializing create_model()
2024-10-02 11:46:28,846:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17dd4e8c0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17207ca90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:46:28,846:INFO:Checking exceptions
2024-10-02 11:46:28,846:INFO:Importing libraries
2024-10-02 11:46:28,846:INFO:Copying training dataset
2024-10-02 11:46:28,848:INFO:Defining folds
2024-10-02 11:46:28,848:INFO:Declaring metric variables
2024-10-02 11:46:28,848:INFO:Importing untrained model
2024-10-02 11:46:28,848:INFO:Ada Boost Classifier Imported successfully
2024-10-02 11:46:28,848:INFO:Starting cross validation
2024-10-02 11:46:28,848:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:46:28,850:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2024-10-02 11:46:28,858:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:46:28,862:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:46:28,863:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:46:28,864:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:46:28,873:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:46:28,873:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:46:28,889:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:46:28,892:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:46:28,931:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,931:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,932:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,932:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,932:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,933:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,933:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,933:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,934:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,934:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,934:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,934:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,935:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,935:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,936:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,936:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,936:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,937:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,937:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,937:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,938:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,938:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,938:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,938:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,938:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,939:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,939:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,939:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,939:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,940:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,940:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,940:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,940:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,942:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,942:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,943:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:46:28,944:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,945:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:46:28,945:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,947:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,947:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,948:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,948:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,949:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,960:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,960:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,961:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,961:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,962:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,962:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,962:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,963:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,964:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,964:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,965:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,965:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,965:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,966:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,994:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,994:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,995:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,995:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,996:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,996:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,996:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,998:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:28,998:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,999:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:28,999:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:28,999:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:29,000:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:29,000:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:29,010:INFO:Calculating mean and std
2024-10-02 11:46:29,010:INFO:Creating metrics dataframe
2024-10-02 11:46:29,011:INFO:Uploading results into container
2024-10-02 11:46:29,011:INFO:Uploading model into container now
2024-10-02 11:46:29,011:INFO:_master_model_container: 9
2024-10-02 11:46:29,011:INFO:_display_container: 2
2024-10-02 11:46:29,011:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8565)
2024-10-02 11:46:29,011:INFO:create_model() successfully completed......................................
2024-10-02 11:46:29,050:INFO:SubProcess create_model() end ==================================
2024-10-02 11:46:29,050:INFO:Creating metrics dataframe
2024-10-02 11:46:29,051:INFO:Initializing Gradient Boosting Classifier
2024-10-02 11:46:29,051:INFO:Total runtime is 0.07192664543787639 minutes
2024-10-02 11:46:29,051:INFO:SubProcess create_model() called ==================================
2024-10-02 11:46:29,051:INFO:Initializing create_model()
2024-10-02 11:46:29,051:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17dd4e8c0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17207ca90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:46:29,051:INFO:Checking exceptions
2024-10-02 11:46:29,051:INFO:Importing libraries
2024-10-02 11:46:29,052:INFO:Copying training dataset
2024-10-02 11:46:29,053:INFO:Defining folds
2024-10-02 11:46:29,053:INFO:Declaring metric variables
2024-10-02 11:46:29,053:INFO:Importing untrained model
2024-10-02 11:46:29,053:INFO:Gradient Boosting Classifier Imported successfully
2024-10-02 11:46:29,053:INFO:Starting cross validation
2024-10-02 11:46:29,054:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:46:29,055:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2024-10-02 11:46:32,684:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:32,685:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:32,685:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:32,686:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:32,686:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:32,687:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:32,687:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:32,700:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:32,700:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:32,701:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:32,701:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:32,702:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:32,702:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:32,702:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:32,786:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:32,786:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:32,787:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:32,787:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:32,788:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:32,788:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:32,788:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:32,789:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:32,789:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:32,789:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:32,790:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:32,790:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:32,791:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:32,792:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:32,930:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:32,930:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:32,931:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:32,931:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:32,932:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:32,932:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:32,933:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:32,969:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:32,969:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:32,970:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:32,970:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:32,970:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:32,971:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:32,971:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:33,031:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:33,031:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:33,032:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:33,032:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:33,033:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:33,033:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:33,034:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:33,083:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:33,083:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:33,084:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:33,084:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:33,085:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:33,085:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:33,086:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,333:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:35,334:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,334:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,334:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,335:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,335:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,336:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,339:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:35,339:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,339:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,340:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,340:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,341:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,341:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,347:INFO:Calculating mean and std
2024-10-02 11:46:35,348:INFO:Creating metrics dataframe
2024-10-02 11:46:35,352:INFO:Uploading results into container
2024-10-02 11:46:35,353:INFO:Uploading model into container now
2024-10-02 11:46:35,353:INFO:_master_model_container: 10
2024-10-02 11:46:35,353:INFO:_display_container: 2
2024-10-02 11:46:35,354:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8565, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-10-02 11:46:35,354:INFO:create_model() successfully completed......................................
2024-10-02 11:46:35,427:INFO:SubProcess create_model() end ==================================
2024-10-02 11:46:35,427:INFO:Creating metrics dataframe
2024-10-02 11:46:35,428:INFO:Initializing Linear Discriminant Analysis
2024-10-02 11:46:35,428:INFO:Total runtime is 0.17821301619211832 minutes
2024-10-02 11:46:35,428:INFO:SubProcess create_model() called ==================================
2024-10-02 11:46:35,429:INFO:Initializing create_model()
2024-10-02 11:46:35,429:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17dd4e8c0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17207ca90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:46:35,429:INFO:Checking exceptions
2024-10-02 11:46:35,429:INFO:Importing libraries
2024-10-02 11:46:35,429:INFO:Copying training dataset
2024-10-02 11:46:35,430:INFO:Defining folds
2024-10-02 11:46:35,430:INFO:Declaring metric variables
2024-10-02 11:46:35,430:INFO:Importing untrained model
2024-10-02 11:46:35,430:INFO:Linear Discriminant Analysis Imported successfully
2024-10-02 11:46:35,430:INFO:Starting cross validation
2024-10-02 11:46:35,431:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:46:35,432:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2024-10-02 11:46:35,448:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:35,449:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,449:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:35,449:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:35,449:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,449:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,449:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,449:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,449:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:35,450:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,450:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,450:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,450:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,450:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,450:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,450:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,450:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,450:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,451:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,451:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,451:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,451:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,451:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,451:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,451:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,452:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,452:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,452:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,459:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:35,459:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:35,459:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,459:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,460:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,460:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,460:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,460:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,461:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,461:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,461:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,461:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,461:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:35,462:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,462:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,462:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,462:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,463:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,463:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:35,463:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,463:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,464:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,464:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,464:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:35,464:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,465:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,465:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,466:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,466:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,467:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,467:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,467:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-10-02 11:46:35,468:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,468:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,468:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,469:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,469:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,469:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,470:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,470:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,471:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,471:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,483:INFO:Calculating mean and std
2024-10-02 11:46:35,484:INFO:Creating metrics dataframe
2024-10-02 11:46:35,484:INFO:Uploading results into container
2024-10-02 11:46:35,485:INFO:Uploading model into container now
2024-10-02 11:46:35,485:INFO:_master_model_container: 11
2024-10-02 11:46:35,485:INFO:_display_container: 2
2024-10-02 11:46:35,485:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-10-02 11:46:35,485:INFO:create_model() successfully completed......................................
2024-10-02 11:46:35,521:INFO:SubProcess create_model() end ==================================
2024-10-02 11:46:35,521:INFO:Creating metrics dataframe
2024-10-02 11:46:35,522:INFO:Initializing Extra Trees Classifier
2024-10-02 11:46:35,522:INFO:Total runtime is 0.1797787626584371 minutes
2024-10-02 11:46:35,522:INFO:SubProcess create_model() called ==================================
2024-10-02 11:46:35,522:INFO:Initializing create_model()
2024-10-02 11:46:35,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17dd4e8c0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17207ca90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:46:35,522:INFO:Checking exceptions
2024-10-02 11:46:35,523:INFO:Importing libraries
2024-10-02 11:46:35,523:INFO:Copying training dataset
2024-10-02 11:46:35,524:INFO:Defining folds
2024-10-02 11:46:35,524:INFO:Declaring metric variables
2024-10-02 11:46:35,524:INFO:Importing untrained model
2024-10-02 11:46:35,524:INFO:Extra Trees Classifier Imported successfully
2024-10-02 11:46:35,524:INFO:Starting cross validation
2024-10-02 11:46:35,525:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:46:35,526:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2024-10-02 11:46:35,708:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:35,709:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,710:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,710:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,711:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,711:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,711:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:35,711:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,713:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,714:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,716:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,716:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,719:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,720:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,721:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:35,721:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,722:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,723:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,724:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,724:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,725:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,725:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:35,726:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,727:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,727:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,728:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,728:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,729:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,731:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:35,732:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,732:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,733:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,733:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,733:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,734:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,738:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:35,739:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,740:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,741:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,741:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,742:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,742:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,743:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:35,744:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,744:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,745:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,745:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,746:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,746:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,753:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:35,754:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,754:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,755:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,755:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,755:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,756:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,812:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:35,812:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,813:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,813:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,814:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,814:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,815:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,824:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:46:35,825:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,825:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,826:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,826:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,827:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:46:35,827:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:46:35,831:INFO:Calculating mean and std
2024-10-02 11:46:35,832:INFO:Creating metrics dataframe
2024-10-02 11:46:35,832:INFO:Uploading results into container
2024-10-02 11:46:35,833:INFO:Uploading model into container now
2024-10-02 11:46:35,833:INFO:_master_model_container: 12
2024-10-02 11:46:35,833:INFO:_display_container: 2
2024-10-02 11:46:35,833:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8565, verbose=0,
                     warm_start=False)
2024-10-02 11:46:35,833:INFO:create_model() successfully completed......................................
2024-10-02 11:46:35,870:INFO:SubProcess create_model() end ==================================
2024-10-02 11:46:35,870:INFO:Creating metrics dataframe
2024-10-02 11:46:35,871:INFO:Initializing Light Gradient Boosting Machine
2024-10-02 11:46:35,871:INFO:Total runtime is 0.18558521270751954 minutes
2024-10-02 11:46:35,871:INFO:SubProcess create_model() called ==================================
2024-10-02 11:46:35,871:INFO:Initializing create_model()
2024-10-02 11:46:35,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17dd4e8c0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17207ca90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:46:35,871:INFO:Checking exceptions
2024-10-02 11:46:35,871:INFO:Importing libraries
2024-10-02 11:46:35,871:INFO:Copying training dataset
2024-10-02 11:46:35,872:INFO:Defining folds
2024-10-02 11:46:35,872:INFO:Declaring metric variables
2024-10-02 11:46:35,872:INFO:Importing untrained model
2024-10-02 11:46:35,873:INFO:Light Gradient Boosting Machine Imported successfully
2024-10-02 11:46:35,873:INFO:Starting cross validation
2024-10-02 11:46:35,873:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:46:35,874:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2024-10-02 11:47:15,977:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:47:15,978:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:15,979:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:15,979:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:15,979:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:15,980:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:15,980:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:17,156:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:47:17,157:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:17,158:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:17,158:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:17,158:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:17,159:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:17,159:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:17,309:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:47:17,310:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:17,311:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:17,311:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:17,312:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:17,312:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:17,313:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:17,466:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:47:17,467:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:17,467:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:17,468:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:17,468:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:17,469:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:17,469:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:17,733:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:47:17,735:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:17,736:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:17,738:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:17,739:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:17,738:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:47:17,740:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:17,742:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:17,752:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:17,758:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:17,765:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:17,770:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:17,776:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:17,782:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:18,465:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:47:18,465:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:18,466:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:18,467:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:18,467:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:18,467:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:18,468:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:18,978:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:47:18,979:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:18,980:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:18,981:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:18,982:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:18,982:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:18,983:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,138:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:47:25,140:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,140:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,141:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,141:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,142:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,142:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,709:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:47:25,709:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,710:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,710:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,711:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,711:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,711:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,714:INFO:Calculating mean and std
2024-10-02 11:47:25,714:INFO:Creating metrics dataframe
2024-10-02 11:47:25,717:INFO:Uploading results into container
2024-10-02 11:47:25,717:INFO:Uploading model into container now
2024-10-02 11:47:25,718:INFO:_master_model_container: 13
2024-10-02 11:47:25,718:INFO:_display_container: 2
2024-10-02 11:47:25,718:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8565, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-10-02 11:47:25,718:INFO:create_model() successfully completed......................................
2024-10-02 11:47:25,809:INFO:SubProcess create_model() end ==================================
2024-10-02 11:47:25,809:INFO:Creating metrics dataframe
2024-10-02 11:47:25,810:INFO:Initializing Dummy Classifier
2024-10-02 11:47:25,810:INFO:Total runtime is 1.0179067810376485 minutes
2024-10-02 11:47:25,810:INFO:SubProcess create_model() called ==================================
2024-10-02 11:47:25,810:INFO:Initializing create_model()
2024-10-02 11:47:25,810:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17dd4e8c0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x17207ca90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:47:25,810:INFO:Checking exceptions
2024-10-02 11:47:25,810:INFO:Importing libraries
2024-10-02 11:47:25,810:INFO:Copying training dataset
2024-10-02 11:47:25,812:INFO:Defining folds
2024-10-02 11:47:25,812:INFO:Declaring metric variables
2024-10-02 11:47:25,812:INFO:Importing untrained model
2024-10-02 11:47:25,812:INFO:Dummy Classifier Imported successfully
2024-10-02 11:47:25,812:INFO:Starting cross validation
2024-10-02 11:47:25,812:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:47:25,814:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/model_selection/_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=10.
  warnings.warn(

2024-10-02 11:47:25,824:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:47:25,825:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,825:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,826:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,826:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,826:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,827:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,828:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:47:25,829:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,829:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,830:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,830:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,831:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,831:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,834:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:47:25,834:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,836:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,837:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,837:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,838:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,838:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,842:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:47:25,843:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,843:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,843:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:47:25,844:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,844:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,844:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,844:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,845:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,845:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,845:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,845:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,846:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,847:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:47:25,847:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,847:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,848:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,848:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,848:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:47:25,848:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:47:25,848:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,849:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,849:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,849:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,849:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,849:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,849:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,850:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,850:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,850:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,850:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,850:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,850:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,851:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,851:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,851:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:47:25,852:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,852:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,852:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,853:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,853:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,854:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,854:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 751, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Number of classes in y_true not equal to the number of columns in 'y_score'

  warnings.warn(

2024-10-02 11:47:25,854:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,855:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,855:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,856:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,856:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 77) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-10-02 11:47:25,856:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:47:25,864:INFO:Calculating mean and std
2024-10-02 11:47:25,864:INFO:Creating metrics dataframe
2024-10-02 11:47:25,865:INFO:Uploading results into container
2024-10-02 11:47:25,865:INFO:Uploading model into container now
2024-10-02 11:47:25,865:INFO:_master_model_container: 14
2024-10-02 11:47:25,865:INFO:_display_container: 2
2024-10-02 11:47:25,865:INFO:DummyClassifier(constant=None, random_state=8565, strategy='prior')
2024-10-02 11:47:25,865:INFO:create_model() successfully completed......................................
2024-10-02 11:47:25,902:INFO:SubProcess create_model() end ==================================
2024-10-02 11:47:25,902:INFO:Creating metrics dataframe
2024-10-02 11:47:25,905:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-10-02 11:47:25,905:INFO:Initializing create_model()
2024-10-02 11:47:25,905:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17dd4e8c0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8565, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:47:25,905:INFO:Checking exceptions
2024-10-02 11:47:25,905:INFO:Importing libraries
2024-10-02 11:47:25,906:INFO:Copying training dataset
2024-10-02 11:47:25,907:INFO:Defining folds
2024-10-02 11:47:25,907:INFO:Declaring metric variables
2024-10-02 11:47:25,907:INFO:Importing untrained model
2024-10-02 11:47:25,907:INFO:Declaring custom model
2024-10-02 11:47:25,907:INFO:Decision Tree Classifier Imported successfully
2024-10-02 11:47:25,907:INFO:Cross validation set to False
2024-10-02 11:47:25,907:INFO:Fitting Model
2024-10-02 11:47:25,913:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8565, splitter='best')
2024-10-02 11:47:25,913:INFO:create_model() successfully completed......................................
2024-10-02 11:47:25,952:INFO:_master_model_container: 14
2024-10-02 11:47:25,952:INFO:_display_container: 2
2024-10-02 11:47:25,953:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8565, splitter='best')
2024-10-02 11:47:25,953:INFO:compare_models() successfully completed......................................
2024-10-02 11:49:38,405:INFO:PyCaret ClassificationExperiment
2024-10-02 11:49:38,405:INFO:Logging name: clf-default-name
2024-10-02 11:49:38,405:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-10-02 11:49:38,406:INFO:version 3.3.2
2024-10-02 11:49:38,406:INFO:Initializing setup()
2024-10-02 11:49:38,406:INFO:self.USI: 75c0
2024-10-02 11:49:38,406:INFO:self._variable_keys: {'y_train', 'logging_param', 'fold_shuffle_param', '_ml_usecase', 'n_jobs_param', 'fold_generator', 'idx', 'data', 'pipeline', 'exp_name_log', 'X', 'gpu_param', 'html_param', 'gpu_n_jobs_param', 'target_param', 'y_test', 'fix_imbalance', 'X_test', 'fold_groups_param', 'log_plots_param', 'exp_id', 'y', 'X_train', '_available_plots', 'USI', 'memory', 'is_multiclass', 'seed'}
2024-10-02 11:49:38,406:INFO:Checking environment
2024-10-02 11:49:38,406:INFO:python_version: 3.10.9
2024-10-02 11:49:38,406:INFO:python_build: ('v3.10.9:1dd9be6584', 'Dec  6 2022 14:37:36')
2024-10-02 11:49:38,406:INFO:machine: arm64
2024-10-02 11:49:38,406:INFO:platform: macOS-13.5.1-arm64-arm-64bit
2024-10-02 11:49:38,407:INFO:Memory: svmem(total=8589934592, available=1290731520, percent=85.0, used=2904719360, free=48300032, active=1259208704, inactive=1129742336, wired=1645510656)
2024-10-02 11:49:38,407:INFO:Physical Core: 8
2024-10-02 11:49:38,407:INFO:Logical Core: 8
2024-10-02 11:49:38,407:INFO:Checking libraries
2024-10-02 11:49:38,407:INFO:System:
2024-10-02 11:49:38,407:INFO:    python: 3.10.9 (v3.10.9:1dd9be6584, Dec  6 2022, 14:37:36) [Clang 13.0.0 (clang-1300.0.29.30)]
2024-10-02 11:49:38,407:INFO:executable: /Users/pratek/test1/Report/.venv/bin/python
2024-10-02 11:49:38,407:INFO:   machine: macOS-13.5.1-arm64-arm-64bit
2024-10-02 11:49:38,407:INFO:PyCaret required dependencies:
2024-10-02 11:49:38,408:INFO:                 pip: 24.2
2024-10-02 11:49:38,408:INFO:          setuptools: 68.2.0
2024-10-02 11:49:38,408:INFO:             pycaret: 3.3.2
2024-10-02 11:49:38,408:INFO:             IPython: 8.27.0
2024-10-02 11:49:38,408:INFO:          ipywidgets: 8.1.5
2024-10-02 11:49:38,408:INFO:                tqdm: 4.66.5
2024-10-02 11:49:38,408:INFO:               numpy: 1.26.4
2024-10-02 11:49:38,408:INFO:              pandas: 2.1.4
2024-10-02 11:49:38,408:INFO:              jinja2: 3.1.4
2024-10-02 11:49:38,408:INFO:               scipy: 1.11.4
2024-10-02 11:49:38,408:INFO:              joblib: 1.3.2
2024-10-02 11:49:38,408:INFO:             sklearn: 1.4.2
2024-10-02 11:49:38,408:INFO:                pyod: 2.0.2
2024-10-02 11:49:38,408:INFO:            imblearn: 0.12.3
2024-10-02 11:49:38,408:INFO:   category_encoders: 2.6.4
2024-10-02 11:49:38,408:INFO:            lightgbm: 4.5.0
2024-10-02 11:49:38,408:INFO:               numba: 0.60.0
2024-10-02 11:49:38,408:INFO:            requests: 2.32.3
2024-10-02 11:49:38,408:INFO:          matplotlib: 3.7.5
2024-10-02 11:49:38,408:INFO:          scikitplot: 0.3.7
2024-10-02 11:49:38,408:INFO:         yellowbrick: 1.5
2024-10-02 11:49:38,408:INFO:              plotly: 5.24.1
2024-10-02 11:49:38,408:INFO:    plotly-resampler: Not installed
2024-10-02 11:49:38,408:INFO:             kaleido: 0.2.1
2024-10-02 11:49:38,408:INFO:           schemdraw: 0.15
2024-10-02 11:49:38,408:INFO:         statsmodels: 0.14.3
2024-10-02 11:49:38,408:INFO:              sktime: 0.26.0
2024-10-02 11:49:38,408:INFO:               tbats: 1.1.3
2024-10-02 11:49:38,408:INFO:            pmdarima: 2.0.4
2024-10-02 11:49:38,408:INFO:              psutil: 6.0.0
2024-10-02 11:49:38,409:INFO:          markupsafe: 2.1.5
2024-10-02 11:49:38,409:INFO:             pickle5: Not installed
2024-10-02 11:49:38,409:INFO:         cloudpickle: 3.0.0
2024-10-02 11:49:38,409:INFO:         deprecation: 2.1.0
2024-10-02 11:49:38,409:INFO:              xxhash: 3.5.0
2024-10-02 11:49:38,409:INFO:           wurlitzer: 3.1.1
2024-10-02 11:49:38,409:INFO:PyCaret optional dependencies:
2024-10-02 11:49:38,409:INFO:                shap: Not installed
2024-10-02 11:49:38,409:INFO:           interpret: Not installed
2024-10-02 11:49:38,409:INFO:                umap: Not installed
2024-10-02 11:49:38,409:INFO:     ydata_profiling: 4.10.0
2024-10-02 11:49:38,409:INFO:  explainerdashboard: Not installed
2024-10-02 11:49:38,409:INFO:             autoviz: Not installed
2024-10-02 11:49:38,409:INFO:           fairlearn: Not installed
2024-10-02 11:49:38,409:INFO:          deepchecks: Not installed
2024-10-02 11:49:38,409:INFO:             xgboost: Not installed
2024-10-02 11:49:38,410:INFO:            catboost: Not installed
2024-10-02 11:49:38,410:INFO:              kmodes: Not installed
2024-10-02 11:49:38,410:INFO:             mlxtend: Not installed
2024-10-02 11:49:38,410:INFO:       statsforecast: Not installed
2024-10-02 11:49:38,410:INFO:        tune_sklearn: Not installed
2024-10-02 11:49:38,410:INFO:                 ray: Not installed
2024-10-02 11:49:38,410:INFO:            hyperopt: Not installed
2024-10-02 11:49:38,410:INFO:              optuna: Not installed
2024-10-02 11:49:38,410:INFO:               skopt: Not installed
2024-10-02 11:49:38,410:INFO:              mlflow: Not installed
2024-10-02 11:49:38,410:INFO:              gradio: Not installed
2024-10-02 11:49:38,410:INFO:             fastapi: Not installed
2024-10-02 11:49:38,410:INFO:             uvicorn: Not installed
2024-10-02 11:49:38,410:INFO:              m2cgen: Not installed
2024-10-02 11:49:38,410:INFO:           evidently: Not installed
2024-10-02 11:49:38,410:INFO:               fugue: Not installed
2024-10-02 11:49:38,410:INFO:           streamlit: 1.39.0
2024-10-02 11:49:38,410:INFO:             prophet: Not installed
2024-10-02 11:49:38,410:INFO:None
2024-10-02 11:49:38,410:INFO:Set up data.
2024-10-02 11:49:38,421:INFO:Set up folding strategy.
2024-10-02 11:49:38,422:INFO:Set up train/test split.
2024-10-02 11:49:38,430:INFO:Set up index.
2024-10-02 11:49:38,430:INFO:Assigning column types.
2024-10-02 11:49:38,435:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-10-02 11:49:38,461:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-02 11:49:38,462:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-02 11:49:38,475:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:49:38,475:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:49:38,493:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-02 11:49:38,493:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-02 11:49:38,504:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:49:38,504:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:49:38,504:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-10-02 11:49:38,523:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-02 11:49:38,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:49:38,533:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:49:38,552:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-02 11:49:38,562:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:49:38,562:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:49:38,562:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-10-02 11:49:38,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:49:38,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:49:38,619:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:49:38,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:49:38,619:INFO:Preparing preprocessing pipeline...
2024-10-02 11:49:38,621:INFO:Set up simple imputation.
2024-10-02 11:49:38,629:INFO:Finished creating preprocessing pipeline.
2024-10-02 11:49:38,631:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/tx/71pw4d8d2l95h2ffhyf9cq340000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'sex', 'cp', 'trestbps',
                                             'chol', 'fbs', 'restecg',
                                             'thalach', 'exang', 'oldpeak',
                                             'slope', 'ca', 'thal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-10-02 11:49:38,631:INFO:Creating final display dataframe.
2024-10-02 11:49:38,657:INFO:Setup _display_container:                     Description             Value
0                    Session id              1755
1                        Target            target
2                   Target type            Binary
3           Original data shape        (1025, 14)
4        Transformed data shape        (1025, 14)
5   Transformed train set shape         (717, 14)
6    Transformed test set shape         (308, 14)
7              Numeric features                13
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              75c0
2024-10-02 11:49:38,687:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:49:38,687:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:49:38,715:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:49:38,715:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:49:38,716:INFO:setup() successfully completed in 0.31s...............
2024-10-02 11:49:38,721:INFO:Initializing compare_models()
2024-10-02 11:49:38,721:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17de65090>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x17de65090>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-10-02 11:49:38,721:INFO:Checking exceptions
2024-10-02 11:49:38,723:INFO:Preparing display monitor
2024-10-02 11:49:38,725:INFO:Initializing Logistic Regression
2024-10-02 11:49:38,725:INFO:Total runtime is 6.198883056640625e-07 minutes
2024-10-02 11:49:38,725:INFO:SubProcess create_model() called ==================================
2024-10-02 11:49:38,725:INFO:Initializing create_model()
2024-10-02 11:49:38,725:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17de65090>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1038c7e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:49:38,725:INFO:Checking exceptions
2024-10-02 11:49:38,725:INFO:Importing libraries
2024-10-02 11:49:38,725:INFO:Copying training dataset
2024-10-02 11:49:38,727:INFO:Defining folds
2024-10-02 11:49:38,727:INFO:Declaring metric variables
2024-10-02 11:49:38,727:INFO:Importing untrained model
2024-10-02 11:49:38,727:INFO:Logistic Regression Imported successfully
2024-10-02 11:49:38,727:INFO:Starting cross validation
2024-10-02 11:49:38,727:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:49:38,892:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-10-02 11:49:38,904:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-10-02 11:49:38,904:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-10-02 11:49:38,973:INFO:Calculating mean and std
2024-10-02 11:49:38,973:INFO:Creating metrics dataframe
2024-10-02 11:49:38,974:INFO:Uploading results into container
2024-10-02 11:49:38,974:INFO:Uploading model into container now
2024-10-02 11:49:38,975:INFO:_master_model_container: 1
2024-10-02 11:49:38,975:INFO:_display_container: 2
2024-10-02 11:49:38,975:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1755, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-10-02 11:49:38,975:INFO:create_model() successfully completed......................................
2024-10-02 11:49:39,020:INFO:SubProcess create_model() end ==================================
2024-10-02 11:49:39,020:INFO:Creating metrics dataframe
2024-10-02 11:49:39,021:INFO:Initializing K Neighbors Classifier
2024-10-02 11:49:39,022:INFO:Total runtime is 0.004942186673482259 minutes
2024-10-02 11:49:39,022:INFO:SubProcess create_model() called ==================================
2024-10-02 11:49:39,022:INFO:Initializing create_model()
2024-10-02 11:49:39,022:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17de65090>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1038c7e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:49:39,022:INFO:Checking exceptions
2024-10-02 11:49:39,022:INFO:Importing libraries
2024-10-02 11:49:39,022:INFO:Copying training dataset
2024-10-02 11:49:39,023:INFO:Defining folds
2024-10-02 11:49:39,023:INFO:Declaring metric variables
2024-10-02 11:49:39,023:INFO:Importing untrained model
2024-10-02 11:49:39,023:INFO:K Neighbors Classifier Imported successfully
2024-10-02 11:49:39,024:INFO:Starting cross validation
2024-10-02 11:49:39,024:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:49:39,129:INFO:Calculating mean and std
2024-10-02 11:49:39,129:INFO:Creating metrics dataframe
2024-10-02 11:49:39,130:INFO:Uploading results into container
2024-10-02 11:49:39,130:INFO:Uploading model into container now
2024-10-02 11:49:39,130:INFO:_master_model_container: 2
2024-10-02 11:49:39,130:INFO:_display_container: 2
2024-10-02 11:49:39,130:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-10-02 11:49:39,130:INFO:create_model() successfully completed......................................
2024-10-02 11:49:39,169:INFO:SubProcess create_model() end ==================================
2024-10-02 11:49:39,169:INFO:Creating metrics dataframe
2024-10-02 11:49:39,170:INFO:Initializing Naive Bayes
2024-10-02 11:49:39,170:INFO:Total runtime is 0.007423635323842367 minutes
2024-10-02 11:49:39,170:INFO:SubProcess create_model() called ==================================
2024-10-02 11:49:39,171:INFO:Initializing create_model()
2024-10-02 11:49:39,171:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17de65090>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1038c7e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:49:39,171:INFO:Checking exceptions
2024-10-02 11:49:39,171:INFO:Importing libraries
2024-10-02 11:49:39,171:INFO:Copying training dataset
2024-10-02 11:49:39,172:INFO:Defining folds
2024-10-02 11:49:39,172:INFO:Declaring metric variables
2024-10-02 11:49:39,172:INFO:Importing untrained model
2024-10-02 11:49:39,172:INFO:Naive Bayes Imported successfully
2024-10-02 11:49:39,172:INFO:Starting cross validation
2024-10-02 11:49:39,173:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:49:39,230:INFO:Calculating mean and std
2024-10-02 11:49:39,230:INFO:Creating metrics dataframe
2024-10-02 11:49:39,231:INFO:Uploading results into container
2024-10-02 11:49:39,231:INFO:Uploading model into container now
2024-10-02 11:49:39,232:INFO:_master_model_container: 3
2024-10-02 11:49:39,232:INFO:_display_container: 2
2024-10-02 11:49:39,232:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-10-02 11:49:39,232:INFO:create_model() successfully completed......................................
2024-10-02 11:49:39,270:INFO:SubProcess create_model() end ==================================
2024-10-02 11:49:39,271:INFO:Creating metrics dataframe
2024-10-02 11:49:39,272:INFO:Initializing Decision Tree Classifier
2024-10-02 11:49:39,272:INFO:Total runtime is 0.009111082553863526 minutes
2024-10-02 11:49:39,272:INFO:SubProcess create_model() called ==================================
2024-10-02 11:49:39,272:INFO:Initializing create_model()
2024-10-02 11:49:39,272:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17de65090>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1038c7e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:49:39,272:INFO:Checking exceptions
2024-10-02 11:49:39,272:INFO:Importing libraries
2024-10-02 11:49:39,272:INFO:Copying training dataset
2024-10-02 11:49:39,273:INFO:Defining folds
2024-10-02 11:49:39,273:INFO:Declaring metric variables
2024-10-02 11:49:39,273:INFO:Importing untrained model
2024-10-02 11:49:39,273:INFO:Decision Tree Classifier Imported successfully
2024-10-02 11:49:39,274:INFO:Starting cross validation
2024-10-02 11:49:39,274:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:49:39,326:INFO:Calculating mean and std
2024-10-02 11:49:39,326:INFO:Creating metrics dataframe
2024-10-02 11:49:39,327:INFO:Uploading results into container
2024-10-02 11:49:39,327:INFO:Uploading model into container now
2024-10-02 11:49:39,327:INFO:_master_model_container: 4
2024-10-02 11:49:39,327:INFO:_display_container: 2
2024-10-02 11:49:39,328:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1755, splitter='best')
2024-10-02 11:49:39,328:INFO:create_model() successfully completed......................................
2024-10-02 11:49:39,366:INFO:SubProcess create_model() end ==================================
2024-10-02 11:49:39,366:INFO:Creating metrics dataframe
2024-10-02 11:49:39,367:INFO:Initializing SVM - Linear Kernel
2024-10-02 11:49:39,367:INFO:Total runtime is 0.010699049631754557 minutes
2024-10-02 11:49:39,367:INFO:SubProcess create_model() called ==================================
2024-10-02 11:49:39,367:INFO:Initializing create_model()
2024-10-02 11:49:39,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17de65090>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1038c7e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:49:39,367:INFO:Checking exceptions
2024-10-02 11:49:39,367:INFO:Importing libraries
2024-10-02 11:49:39,367:INFO:Copying training dataset
2024-10-02 11:49:39,369:INFO:Defining folds
2024-10-02 11:49:39,369:INFO:Declaring metric variables
2024-10-02 11:49:39,369:INFO:Importing untrained model
2024-10-02 11:49:39,369:INFO:SVM - Linear Kernel Imported successfully
2024-10-02 11:49:39,369:INFO:Starting cross validation
2024-10-02 11:49:39,369:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:49:39,409:INFO:Calculating mean and std
2024-10-02 11:49:39,409:INFO:Creating metrics dataframe
2024-10-02 11:49:39,410:INFO:Uploading results into container
2024-10-02 11:49:39,410:INFO:Uploading model into container now
2024-10-02 11:49:39,411:INFO:_master_model_container: 5
2024-10-02 11:49:39,411:INFO:_display_container: 2
2024-10-02 11:49:39,411:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1755, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-10-02 11:49:39,411:INFO:create_model() successfully completed......................................
2024-10-02 11:49:39,454:INFO:SubProcess create_model() end ==================================
2024-10-02 11:49:39,454:INFO:Creating metrics dataframe
2024-10-02 11:49:39,455:INFO:Initializing Ridge Classifier
2024-10-02 11:49:39,455:INFO:Total runtime is 0.012170553207397461 minutes
2024-10-02 11:49:39,455:INFO:SubProcess create_model() called ==================================
2024-10-02 11:49:39,455:INFO:Initializing create_model()
2024-10-02 11:49:39,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17de65090>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1038c7e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:49:39,455:INFO:Checking exceptions
2024-10-02 11:49:39,455:INFO:Importing libraries
2024-10-02 11:49:39,455:INFO:Copying training dataset
2024-10-02 11:49:39,457:INFO:Defining folds
2024-10-02 11:49:39,457:INFO:Declaring metric variables
2024-10-02 11:49:39,457:INFO:Importing untrained model
2024-10-02 11:49:39,457:INFO:Ridge Classifier Imported successfully
2024-10-02 11:49:39,457:INFO:Starting cross validation
2024-10-02 11:49:39,457:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:49:39,497:INFO:Calculating mean and std
2024-10-02 11:49:39,497:INFO:Creating metrics dataframe
2024-10-02 11:49:39,498:INFO:Uploading results into container
2024-10-02 11:49:39,498:INFO:Uploading model into container now
2024-10-02 11:49:39,498:INFO:_master_model_container: 6
2024-10-02 11:49:39,498:INFO:_display_container: 2
2024-10-02 11:49:39,498:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1755, solver='auto',
                tol=0.0001)
2024-10-02 11:49:39,498:INFO:create_model() successfully completed......................................
2024-10-02 11:49:39,541:INFO:SubProcess create_model() end ==================================
2024-10-02 11:49:39,541:INFO:Creating metrics dataframe
2024-10-02 11:49:39,542:INFO:Initializing Random Forest Classifier
2024-10-02 11:49:39,542:INFO:Total runtime is 0.013622550169626872 minutes
2024-10-02 11:49:39,542:INFO:SubProcess create_model() called ==================================
2024-10-02 11:49:39,542:INFO:Initializing create_model()
2024-10-02 11:49:39,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17de65090>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1038c7e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:49:39,543:INFO:Checking exceptions
2024-10-02 11:49:39,543:INFO:Importing libraries
2024-10-02 11:49:39,543:INFO:Copying training dataset
2024-10-02 11:49:39,544:INFO:Defining folds
2024-10-02 11:49:39,544:INFO:Declaring metric variables
2024-10-02 11:49:39,544:INFO:Importing untrained model
2024-10-02 11:49:39,544:INFO:Random Forest Classifier Imported successfully
2024-10-02 11:49:39,544:INFO:Starting cross validation
2024-10-02 11:49:39,545:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:49:39,845:INFO:Calculating mean and std
2024-10-02 11:49:39,846:INFO:Creating metrics dataframe
2024-10-02 11:49:39,846:INFO:Uploading results into container
2024-10-02 11:49:39,847:INFO:Uploading model into container now
2024-10-02 11:49:39,847:INFO:_master_model_container: 7
2024-10-02 11:49:39,847:INFO:_display_container: 2
2024-10-02 11:49:39,847:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1755, verbose=0,
                       warm_start=False)
2024-10-02 11:49:39,847:INFO:create_model() successfully completed......................................
2024-10-02 11:49:39,883:INFO:SubProcess create_model() end ==================================
2024-10-02 11:49:39,883:INFO:Creating metrics dataframe
2024-10-02 11:49:39,885:INFO:Initializing Quadratic Discriminant Analysis
2024-10-02 11:49:39,885:INFO:Total runtime is 0.01932648817698161 minutes
2024-10-02 11:49:39,885:INFO:SubProcess create_model() called ==================================
2024-10-02 11:49:39,885:INFO:Initializing create_model()
2024-10-02 11:49:39,885:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17de65090>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1038c7e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:49:39,885:INFO:Checking exceptions
2024-10-02 11:49:39,885:INFO:Importing libraries
2024-10-02 11:49:39,885:INFO:Copying training dataset
2024-10-02 11:49:39,886:INFO:Defining folds
2024-10-02 11:49:39,886:INFO:Declaring metric variables
2024-10-02 11:49:39,886:INFO:Importing untrained model
2024-10-02 11:49:39,886:INFO:Quadratic Discriminant Analysis Imported successfully
2024-10-02 11:49:39,886:INFO:Starting cross validation
2024-10-02 11:49:39,887:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:49:39,934:INFO:Calculating mean and std
2024-10-02 11:49:39,934:INFO:Creating metrics dataframe
2024-10-02 11:49:39,935:INFO:Uploading results into container
2024-10-02 11:49:39,935:INFO:Uploading model into container now
2024-10-02 11:49:39,935:INFO:_master_model_container: 8
2024-10-02 11:49:39,935:INFO:_display_container: 2
2024-10-02 11:49:39,935:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-10-02 11:49:39,935:INFO:create_model() successfully completed......................................
2024-10-02 11:49:39,971:INFO:SubProcess create_model() end ==================================
2024-10-02 11:49:39,971:INFO:Creating metrics dataframe
2024-10-02 11:49:39,972:INFO:Initializing Ada Boost Classifier
2024-10-02 11:49:39,972:INFO:Total runtime is 0.020778568585713704 minutes
2024-10-02 11:49:39,972:INFO:SubProcess create_model() called ==================================
2024-10-02 11:49:39,972:INFO:Initializing create_model()
2024-10-02 11:49:39,972:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17de65090>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1038c7e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:49:39,972:INFO:Checking exceptions
2024-10-02 11:49:39,972:INFO:Importing libraries
2024-10-02 11:49:39,972:INFO:Copying training dataset
2024-10-02 11:49:39,973:INFO:Defining folds
2024-10-02 11:49:39,973:INFO:Declaring metric variables
2024-10-02 11:49:39,973:INFO:Importing untrained model
2024-10-02 11:49:39,974:INFO:Ada Boost Classifier Imported successfully
2024-10-02 11:49:39,974:INFO:Starting cross validation
2024-10-02 11:49:39,974:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:49:39,982:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:49:39,982:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:49:39,984:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:49:39,990:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:49:39,991:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:49:40,001:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:49:40,008:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:49:40,012:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:49:40,044:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:49:40,046:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:49:40,096:INFO:Calculating mean and std
2024-10-02 11:49:40,096:INFO:Creating metrics dataframe
2024-10-02 11:49:40,097:INFO:Uploading results into container
2024-10-02 11:49:40,097:INFO:Uploading model into container now
2024-10-02 11:49:40,097:INFO:_master_model_container: 9
2024-10-02 11:49:40,097:INFO:_display_container: 2
2024-10-02 11:49:40,097:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1755)
2024-10-02 11:49:40,097:INFO:create_model() successfully completed......................................
2024-10-02 11:49:40,136:INFO:SubProcess create_model() end ==================================
2024-10-02 11:49:40,136:INFO:Creating metrics dataframe
2024-10-02 11:49:40,137:INFO:Initializing Gradient Boosting Classifier
2024-10-02 11:49:40,137:INFO:Total runtime is 0.023531687259674073 minutes
2024-10-02 11:49:40,137:INFO:SubProcess create_model() called ==================================
2024-10-02 11:49:40,137:INFO:Initializing create_model()
2024-10-02 11:49:40,137:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17de65090>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1038c7e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:49:40,137:INFO:Checking exceptions
2024-10-02 11:49:40,137:INFO:Importing libraries
2024-10-02 11:49:40,137:INFO:Copying training dataset
2024-10-02 11:49:40,139:INFO:Defining folds
2024-10-02 11:49:40,139:INFO:Declaring metric variables
2024-10-02 11:49:40,139:INFO:Importing untrained model
2024-10-02 11:49:40,139:INFO:Gradient Boosting Classifier Imported successfully
2024-10-02 11:49:40,139:INFO:Starting cross validation
2024-10-02 11:49:40,139:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:49:40,342:INFO:Calculating mean and std
2024-10-02 11:49:40,343:INFO:Creating metrics dataframe
2024-10-02 11:49:40,343:INFO:Uploading results into container
2024-10-02 11:49:40,343:INFO:Uploading model into container now
2024-10-02 11:49:40,344:INFO:_master_model_container: 10
2024-10-02 11:49:40,344:INFO:_display_container: 2
2024-10-02 11:49:40,344:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1755, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-10-02 11:49:40,344:INFO:create_model() successfully completed......................................
2024-10-02 11:49:40,379:INFO:SubProcess create_model() end ==================================
2024-10-02 11:49:40,379:INFO:Creating metrics dataframe
2024-10-02 11:49:40,381:INFO:Initializing Linear Discriminant Analysis
2024-10-02 11:49:40,381:INFO:Total runtime is 0.027592837810516357 minutes
2024-10-02 11:49:40,381:INFO:SubProcess create_model() called ==================================
2024-10-02 11:49:40,381:INFO:Initializing create_model()
2024-10-02 11:49:40,381:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17de65090>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1038c7e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:49:40,381:INFO:Checking exceptions
2024-10-02 11:49:40,381:INFO:Importing libraries
2024-10-02 11:49:40,381:INFO:Copying training dataset
2024-10-02 11:49:40,382:INFO:Defining folds
2024-10-02 11:49:40,382:INFO:Declaring metric variables
2024-10-02 11:49:40,382:INFO:Importing untrained model
2024-10-02 11:49:40,382:INFO:Linear Discriminant Analysis Imported successfully
2024-10-02 11:49:40,383:INFO:Starting cross validation
2024-10-02 11:49:40,383:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:49:40,431:INFO:Calculating mean and std
2024-10-02 11:49:40,431:INFO:Creating metrics dataframe
2024-10-02 11:49:40,432:INFO:Uploading results into container
2024-10-02 11:49:40,432:INFO:Uploading model into container now
2024-10-02 11:49:40,432:INFO:_master_model_container: 11
2024-10-02 11:49:40,432:INFO:_display_container: 2
2024-10-02 11:49:40,432:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-10-02 11:49:40,432:INFO:create_model() successfully completed......................................
2024-10-02 11:49:40,470:INFO:SubProcess create_model() end ==================================
2024-10-02 11:49:40,470:INFO:Creating metrics dataframe
2024-10-02 11:49:40,471:INFO:Initializing Extra Trees Classifier
2024-10-02 11:49:40,472:INFO:Total runtime is 0.029109366734822593 minutes
2024-10-02 11:49:40,472:INFO:SubProcess create_model() called ==================================
2024-10-02 11:49:40,472:INFO:Initializing create_model()
2024-10-02 11:49:40,472:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17de65090>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1038c7e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:49:40,472:INFO:Checking exceptions
2024-10-02 11:49:40,472:INFO:Importing libraries
2024-10-02 11:49:40,472:INFO:Copying training dataset
2024-10-02 11:49:40,473:INFO:Defining folds
2024-10-02 11:49:40,473:INFO:Declaring metric variables
2024-10-02 11:49:40,473:INFO:Importing untrained model
2024-10-02 11:49:40,473:INFO:Extra Trees Classifier Imported successfully
2024-10-02 11:49:40,473:INFO:Starting cross validation
2024-10-02 11:49:40,474:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:49:40,708:INFO:Calculating mean and std
2024-10-02 11:49:40,709:INFO:Creating metrics dataframe
2024-10-02 11:49:40,709:INFO:Uploading results into container
2024-10-02 11:49:40,709:INFO:Uploading model into container now
2024-10-02 11:49:40,710:INFO:_master_model_container: 12
2024-10-02 11:49:40,710:INFO:_display_container: 2
2024-10-02 11:49:40,710:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1755, verbose=0,
                     warm_start=False)
2024-10-02 11:49:40,710:INFO:create_model() successfully completed......................................
2024-10-02 11:49:40,747:INFO:SubProcess create_model() end ==================================
2024-10-02 11:49:40,748:INFO:Creating metrics dataframe
2024-10-02 11:49:40,749:INFO:Initializing Light Gradient Boosting Machine
2024-10-02 11:49:40,749:INFO:Total runtime is 0.03373766740163167 minutes
2024-10-02 11:49:40,749:INFO:SubProcess create_model() called ==================================
2024-10-02 11:49:40,749:INFO:Initializing create_model()
2024-10-02 11:49:40,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17de65090>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1038c7e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:49:40,749:INFO:Checking exceptions
2024-10-02 11:49:40,749:INFO:Importing libraries
2024-10-02 11:49:40,749:INFO:Copying training dataset
2024-10-02 11:49:40,751:INFO:Defining folds
2024-10-02 11:49:40,751:INFO:Declaring metric variables
2024-10-02 11:49:40,751:INFO:Importing untrained model
2024-10-02 11:49:40,751:INFO:Light Gradient Boosting Machine Imported successfully
2024-10-02 11:49:40,751:INFO:Starting cross validation
2024-10-02 11:49:40,752:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:49:42,340:INFO:Calculating mean and std
2024-10-02 11:49:42,341:INFO:Creating metrics dataframe
2024-10-02 11:49:42,343:INFO:Uploading results into container
2024-10-02 11:49:42,343:INFO:Uploading model into container now
2024-10-02 11:49:42,344:INFO:_master_model_container: 13
2024-10-02 11:49:42,344:INFO:_display_container: 2
2024-10-02 11:49:42,344:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1755, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-10-02 11:49:42,344:INFO:create_model() successfully completed......................................
2024-10-02 11:49:42,404:INFO:SubProcess create_model() end ==================================
2024-10-02 11:49:42,404:INFO:Creating metrics dataframe
2024-10-02 11:49:42,405:INFO:Initializing Dummy Classifier
2024-10-02 11:49:42,405:INFO:Total runtime is 0.06133662064870198 minutes
2024-10-02 11:49:42,405:INFO:SubProcess create_model() called ==================================
2024-10-02 11:49:42,405:INFO:Initializing create_model()
2024-10-02 11:49:42,405:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17de65090>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1038c7e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:49:42,405:INFO:Checking exceptions
2024-10-02 11:49:42,405:INFO:Importing libraries
2024-10-02 11:49:42,406:INFO:Copying training dataset
2024-10-02 11:49:42,407:INFO:Defining folds
2024-10-02 11:49:42,407:INFO:Declaring metric variables
2024-10-02 11:49:42,407:INFO:Importing untrained model
2024-10-02 11:49:42,407:INFO:Dummy Classifier Imported successfully
2024-10-02 11:49:42,407:INFO:Starting cross validation
2024-10-02 11:49:42,407:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:49:42,444:INFO:Calculating mean and std
2024-10-02 11:49:42,445:INFO:Creating metrics dataframe
2024-10-02 11:49:42,445:INFO:Uploading results into container
2024-10-02 11:49:42,445:INFO:Uploading model into container now
2024-10-02 11:49:42,446:INFO:_master_model_container: 14
2024-10-02 11:49:42,446:INFO:_display_container: 2
2024-10-02 11:49:42,446:INFO:DummyClassifier(constant=None, random_state=1755, strategy='prior')
2024-10-02 11:49:42,446:INFO:create_model() successfully completed......................................
2024-10-02 11:49:42,482:INFO:SubProcess create_model() end ==================================
2024-10-02 11:49:42,483:INFO:Creating metrics dataframe
2024-10-02 11:49:42,484:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-10-02 11:49:42,484:INFO:Initializing create_model()
2024-10-02 11:49:42,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x17de65090>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1755, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:49:42,484:INFO:Checking exceptions
2024-10-02 11:49:42,485:INFO:Importing libraries
2024-10-02 11:49:42,485:INFO:Copying training dataset
2024-10-02 11:49:42,486:INFO:Defining folds
2024-10-02 11:49:42,486:INFO:Declaring metric variables
2024-10-02 11:49:42,486:INFO:Importing untrained model
2024-10-02 11:49:42,486:INFO:Declaring custom model
2024-10-02 11:49:42,486:INFO:Extra Trees Classifier Imported successfully
2024-10-02 11:49:42,487:INFO:Cross validation set to False
2024-10-02 11:49:42,487:INFO:Fitting Model
2024-10-02 11:49:42,538:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1755, verbose=0,
                     warm_start=False)
2024-10-02 11:49:42,538:INFO:create_model() successfully completed......................................
2024-10-02 11:49:42,577:INFO:_master_model_container: 14
2024-10-02 11:49:42,578:INFO:_display_container: 2
2024-10-02 11:49:42,578:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1755, verbose=0,
                     warm_start=False)
2024-10-02 11:49:42,578:INFO:compare_models() successfully completed......................................
2024-10-02 11:49:42,581:INFO:Initializing save_model()
2024-10-02 11:49:42,581:INFO:save_model(model=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1755, verbose=0,
                     warm_start=False), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/tx/71pw4d8d2l95h2ffhyf9cq340000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'sex', 'cp', 'trestbps',
                                             'chol', 'fbs', 'restecg',
                                             'thalach', 'exang', 'oldpeak',
                                             'slope', 'ca', 'thal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-10-02 11:49:42,581:INFO:Adding model into prep_pipe
2024-10-02 11:49:42,604:INFO:best_model.pkl saved in current working directory
2024-10-02 11:49:42,606:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'sex', 'cp', 'trestbps',
                                             'chol', 'fbs', 'restecg',
                                             'thalach', 'exang', 'oldpeak',
                                             'slope', 'ca', 'thal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categ...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      monotonic_cst=None, n_estimators=100,
                                      n_jobs=-1, oob_score=False,
                                      random_state=1755, verbose=0,
                                      warm_start=False))],
         verbose=False)
2024-10-02 11:49:42,606:INFO:save_model() successfully completed......................................
2024-10-02 11:51:48,829:INFO:PyCaret ClassificationExperiment
2024-10-02 11:51:48,829:INFO:Logging name: clf-default-name
2024-10-02 11:51:48,829:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-10-02 11:51:48,829:INFO:version 3.3.2
2024-10-02 11:51:48,829:INFO:Initializing setup()
2024-10-02 11:51:48,829:INFO:self.USI: 9ff9
2024-10-02 11:51:48,829:INFO:self._variable_keys: {'y_train', 'logging_param', 'fold_shuffle_param', '_ml_usecase', 'n_jobs_param', 'fold_generator', 'idx', 'data', 'pipeline', 'exp_name_log', 'X', 'gpu_param', 'html_param', 'gpu_n_jobs_param', 'target_param', 'y_test', 'fix_imbalance', 'X_test', 'fold_groups_param', 'log_plots_param', 'exp_id', 'y', 'X_train', '_available_plots', 'USI', 'memory', 'is_multiclass', 'seed'}
2024-10-02 11:51:48,829:INFO:Checking environment
2024-10-02 11:51:48,829:INFO:python_version: 3.10.9
2024-10-02 11:51:48,829:INFO:python_build: ('v3.10.9:1dd9be6584', 'Dec  6 2022 14:37:36')
2024-10-02 11:51:48,829:INFO:machine: arm64
2024-10-02 11:51:48,829:INFO:platform: macOS-13.5.1-arm64-arm-64bit
2024-10-02 11:51:48,830:INFO:Memory: svmem(total=8589934592, available=1357119488, percent=84.2, used=2910208000, free=76021760, active=1296990208, inactive=1278214144, wired=1613217792)
2024-10-02 11:51:48,830:INFO:Physical Core: 8
2024-10-02 11:51:48,830:INFO:Logical Core: 8
2024-10-02 11:51:48,830:INFO:Checking libraries
2024-10-02 11:51:48,830:INFO:System:
2024-10-02 11:51:48,830:INFO:    python: 3.10.9 (v3.10.9:1dd9be6584, Dec  6 2022, 14:37:36) [Clang 13.0.0 (clang-1300.0.29.30)]
2024-10-02 11:51:48,830:INFO:executable: /Users/pratek/test1/Report/.venv/bin/python
2024-10-02 11:51:48,830:INFO:   machine: macOS-13.5.1-arm64-arm-64bit
2024-10-02 11:51:48,830:INFO:PyCaret required dependencies:
2024-10-02 11:51:48,830:INFO:                 pip: 24.2
2024-10-02 11:51:48,830:INFO:          setuptools: 68.2.0
2024-10-02 11:51:48,830:INFO:             pycaret: 3.3.2
2024-10-02 11:51:48,830:INFO:             IPython: 8.27.0
2024-10-02 11:51:48,830:INFO:          ipywidgets: 8.1.5
2024-10-02 11:51:48,830:INFO:                tqdm: 4.66.5
2024-10-02 11:51:48,830:INFO:               numpy: 1.26.4
2024-10-02 11:51:48,830:INFO:              pandas: 2.1.4
2024-10-02 11:51:48,830:INFO:              jinja2: 3.1.4
2024-10-02 11:51:48,830:INFO:               scipy: 1.11.4
2024-10-02 11:51:48,830:INFO:              joblib: 1.3.2
2024-10-02 11:51:48,831:INFO:             sklearn: 1.4.2
2024-10-02 11:51:48,831:INFO:                pyod: 2.0.2
2024-10-02 11:51:48,831:INFO:            imblearn: 0.12.3
2024-10-02 11:51:48,831:INFO:   category_encoders: 2.6.4
2024-10-02 11:51:48,831:INFO:            lightgbm: 4.5.0
2024-10-02 11:51:48,831:INFO:               numba: 0.60.0
2024-10-02 11:51:48,831:INFO:            requests: 2.32.3
2024-10-02 11:51:48,831:INFO:          matplotlib: 3.7.5
2024-10-02 11:51:48,831:INFO:          scikitplot: 0.3.7
2024-10-02 11:51:48,831:INFO:         yellowbrick: 1.5
2024-10-02 11:51:48,831:INFO:              plotly: 5.24.1
2024-10-02 11:51:48,831:INFO:    plotly-resampler: Not installed
2024-10-02 11:51:48,831:INFO:             kaleido: 0.2.1
2024-10-02 11:51:48,831:INFO:           schemdraw: 0.15
2024-10-02 11:51:48,831:INFO:         statsmodels: 0.14.3
2024-10-02 11:51:48,831:INFO:              sktime: 0.26.0
2024-10-02 11:51:48,831:INFO:               tbats: 1.1.3
2024-10-02 11:51:48,831:INFO:            pmdarima: 2.0.4
2024-10-02 11:51:48,831:INFO:              psutil: 6.0.0
2024-10-02 11:51:48,831:INFO:          markupsafe: 2.1.5
2024-10-02 11:51:48,831:INFO:             pickle5: Not installed
2024-10-02 11:51:48,831:INFO:         cloudpickle: 3.0.0
2024-10-02 11:51:48,831:INFO:         deprecation: 2.1.0
2024-10-02 11:51:48,831:INFO:              xxhash: 3.5.0
2024-10-02 11:51:48,831:INFO:           wurlitzer: 3.1.1
2024-10-02 11:51:48,831:INFO:PyCaret optional dependencies:
2024-10-02 11:51:48,831:INFO:                shap: Not installed
2024-10-02 11:51:48,831:INFO:           interpret: Not installed
2024-10-02 11:51:48,831:INFO:                umap: Not installed
2024-10-02 11:51:48,831:INFO:     ydata_profiling: 4.10.0
2024-10-02 11:51:48,831:INFO:  explainerdashboard: Not installed
2024-10-02 11:51:48,832:INFO:             autoviz: Not installed
2024-10-02 11:51:48,832:INFO:           fairlearn: Not installed
2024-10-02 11:51:48,832:INFO:          deepchecks: Not installed
2024-10-02 11:51:48,832:INFO:             xgboost: Not installed
2024-10-02 11:51:48,832:INFO:            catboost: Not installed
2024-10-02 11:51:48,832:INFO:              kmodes: Not installed
2024-10-02 11:51:48,832:INFO:             mlxtend: Not installed
2024-10-02 11:51:48,832:INFO:       statsforecast: Not installed
2024-10-02 11:51:48,832:INFO:        tune_sklearn: Not installed
2024-10-02 11:51:48,832:INFO:                 ray: Not installed
2024-10-02 11:51:48,832:INFO:            hyperopt: Not installed
2024-10-02 11:51:48,832:INFO:              optuna: Not installed
2024-10-02 11:51:48,832:INFO:               skopt: Not installed
2024-10-02 11:51:48,832:INFO:              mlflow: Not installed
2024-10-02 11:51:48,832:INFO:              gradio: Not installed
2024-10-02 11:51:48,832:INFO:             fastapi: Not installed
2024-10-02 11:51:48,832:INFO:             uvicorn: Not installed
2024-10-02 11:51:48,832:INFO:              m2cgen: Not installed
2024-10-02 11:51:48,832:INFO:           evidently: Not installed
2024-10-02 11:51:48,832:INFO:               fugue: Not installed
2024-10-02 11:51:48,832:INFO:           streamlit: 1.39.0
2024-10-02 11:51:48,832:INFO:             prophet: Not installed
2024-10-02 11:51:48,832:INFO:None
2024-10-02 11:51:48,833:INFO:Set up data.
2024-10-02 11:51:48,837:INFO:Set up folding strategy.
2024-10-02 11:51:48,838:INFO:Set up train/test split.
2024-10-02 11:51:48,841:INFO:Set up index.
2024-10-02 11:51:48,841:INFO:Assigning column types.
2024-10-02 11:51:48,847:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-10-02 11:51:48,874:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-02 11:51:48,875:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-02 11:51:48,889:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:51:48,889:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:51:48,908:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-02 11:51:48,908:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-02 11:51:48,919:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:51:48,919:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:51:48,919:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-10-02 11:51:48,937:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-02 11:51:48,948:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:51:48,949:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:51:48,967:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-02 11:51:48,977:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:51:48,978:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:51:48,978:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-10-02 11:51:49,006:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:51:49,006:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:51:49,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:51:49,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:51:49,035:INFO:Preparing preprocessing pipeline...
2024-10-02 11:51:49,036:INFO:Set up simple imputation.
2024-10-02 11:51:49,042:INFO:Finished creating preprocessing pipeline.
2024-10-02 11:51:49,044:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/tx/71pw4d8d2l95h2ffhyf9cq340000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'sex', 'cp', 'trestbps',
                                             'chol', 'fbs', 'restecg',
                                             'thalach', 'exang', 'oldpeak',
                                             'slope', 'ca', 'thal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-10-02 11:51:49,044:INFO:Creating final display dataframe.
2024-10-02 11:51:49,071:INFO:Setup _display_container:                     Description             Value
0                    Session id              2574
1                        Target            target
2                   Target type            Binary
3           Original data shape        (1025, 14)
4        Transformed data shape        (1025, 14)
5   Transformed train set shape         (717, 14)
6    Transformed test set shape         (308, 14)
7              Numeric features                13
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              9ff9
2024-10-02 11:51:49,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:51:49,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:51:49,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:51:49,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:51:49,134:INFO:setup() successfully completed in 0.31s...............
2024-10-02 11:51:49,136:INFO:Initializing compare_models()
2024-10-02 11:51:49,136:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171ed40d0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x171ed40d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-10-02 11:51:49,136:INFO:Checking exceptions
2024-10-02 11:51:49,138:INFO:Preparing display monitor
2024-10-02 11:51:49,139:INFO:Initializing Logistic Regression
2024-10-02 11:51:49,139:INFO:Total runtime is 4.80810801188151e-07 minutes
2024-10-02 11:51:49,139:INFO:SubProcess create_model() called ==================================
2024-10-02 11:51:49,139:INFO:Initializing create_model()
2024-10-02 11:51:49,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171ed40d0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x171ed79a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:51:49,139:INFO:Checking exceptions
2024-10-02 11:51:49,139:INFO:Importing libraries
2024-10-02 11:51:49,139:INFO:Copying training dataset
2024-10-02 11:51:49,140:INFO:Defining folds
2024-10-02 11:51:49,140:INFO:Declaring metric variables
2024-10-02 11:51:49,140:INFO:Importing untrained model
2024-10-02 11:51:49,140:INFO:Logistic Regression Imported successfully
2024-10-02 11:51:49,140:INFO:Starting cross validation
2024-10-02 11:51:49,141:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:51:49,306:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-10-02 11:51:49,330:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-10-02 11:51:49,364:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-10-02 11:51:49,378:INFO:Calculating mean and std
2024-10-02 11:51:49,379:INFO:Creating metrics dataframe
2024-10-02 11:51:49,380:INFO:Uploading results into container
2024-10-02 11:51:49,380:INFO:Uploading model into container now
2024-10-02 11:51:49,380:INFO:_master_model_container: 1
2024-10-02 11:51:49,380:INFO:_display_container: 2
2024-10-02 11:51:49,380:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2574, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-10-02 11:51:49,380:INFO:create_model() successfully completed......................................
2024-10-02 11:51:49,423:INFO:SubProcess create_model() end ==================================
2024-10-02 11:51:49,423:INFO:Creating metrics dataframe
2024-10-02 11:51:49,424:INFO:Initializing K Neighbors Classifier
2024-10-02 11:51:49,424:INFO:Total runtime is 0.004761068026224772 minutes
2024-10-02 11:51:49,424:INFO:SubProcess create_model() called ==================================
2024-10-02 11:51:49,424:INFO:Initializing create_model()
2024-10-02 11:51:49,424:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171ed40d0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x171ed79a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:51:49,424:INFO:Checking exceptions
2024-10-02 11:51:49,424:INFO:Importing libraries
2024-10-02 11:51:49,424:INFO:Copying training dataset
2024-10-02 11:51:49,426:INFO:Defining folds
2024-10-02 11:51:49,426:INFO:Declaring metric variables
2024-10-02 11:51:49,426:INFO:Importing untrained model
2024-10-02 11:51:49,426:INFO:K Neighbors Classifier Imported successfully
2024-10-02 11:51:49,426:INFO:Starting cross validation
2024-10-02 11:51:49,426:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:51:49,521:INFO:Calculating mean and std
2024-10-02 11:51:49,524:INFO:Creating metrics dataframe
2024-10-02 11:51:49,524:INFO:Uploading results into container
2024-10-02 11:51:49,525:INFO:Uploading model into container now
2024-10-02 11:51:49,525:INFO:_master_model_container: 2
2024-10-02 11:51:49,525:INFO:_display_container: 2
2024-10-02 11:51:49,525:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-10-02 11:51:49,525:INFO:create_model() successfully completed......................................
2024-10-02 11:51:49,563:INFO:SubProcess create_model() end ==================================
2024-10-02 11:51:49,563:INFO:Creating metrics dataframe
2024-10-02 11:51:49,564:INFO:Initializing Naive Bayes
2024-10-02 11:51:49,565:INFO:Total runtime is 0.007099032402038574 minutes
2024-10-02 11:51:49,565:INFO:SubProcess create_model() called ==================================
2024-10-02 11:51:49,565:INFO:Initializing create_model()
2024-10-02 11:51:49,565:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171ed40d0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x171ed79a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:51:49,565:INFO:Checking exceptions
2024-10-02 11:51:49,565:INFO:Importing libraries
2024-10-02 11:51:49,565:INFO:Copying training dataset
2024-10-02 11:51:49,566:INFO:Defining folds
2024-10-02 11:51:49,567:INFO:Declaring metric variables
2024-10-02 11:51:49,567:INFO:Importing untrained model
2024-10-02 11:51:49,567:INFO:Naive Bayes Imported successfully
2024-10-02 11:51:49,567:INFO:Starting cross validation
2024-10-02 11:51:49,567:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:51:49,605:INFO:Calculating mean and std
2024-10-02 11:51:49,605:INFO:Creating metrics dataframe
2024-10-02 11:51:49,606:INFO:Uploading results into container
2024-10-02 11:51:49,606:INFO:Uploading model into container now
2024-10-02 11:51:49,606:INFO:_master_model_container: 3
2024-10-02 11:51:49,606:INFO:_display_container: 2
2024-10-02 11:51:49,606:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-10-02 11:51:49,606:INFO:create_model() successfully completed......................................
2024-10-02 11:51:49,644:INFO:SubProcess create_model() end ==================================
2024-10-02 11:51:49,644:INFO:Creating metrics dataframe
2024-10-02 11:51:49,645:INFO:Initializing Decision Tree Classifier
2024-10-02 11:51:49,645:INFO:Total runtime is 0.008447265625 minutes
2024-10-02 11:51:49,645:INFO:SubProcess create_model() called ==================================
2024-10-02 11:51:49,646:INFO:Initializing create_model()
2024-10-02 11:51:49,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171ed40d0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x171ed79a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:51:49,646:INFO:Checking exceptions
2024-10-02 11:51:49,646:INFO:Importing libraries
2024-10-02 11:51:49,646:INFO:Copying training dataset
2024-10-02 11:51:49,647:INFO:Defining folds
2024-10-02 11:51:49,647:INFO:Declaring metric variables
2024-10-02 11:51:49,647:INFO:Importing untrained model
2024-10-02 11:51:49,647:INFO:Decision Tree Classifier Imported successfully
2024-10-02 11:51:49,647:INFO:Starting cross validation
2024-10-02 11:51:49,648:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:51:49,689:INFO:Calculating mean and std
2024-10-02 11:51:49,689:INFO:Creating metrics dataframe
2024-10-02 11:51:49,690:INFO:Uploading results into container
2024-10-02 11:51:49,690:INFO:Uploading model into container now
2024-10-02 11:51:49,690:INFO:_master_model_container: 4
2024-10-02 11:51:49,690:INFO:_display_container: 2
2024-10-02 11:51:49,690:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=2574, splitter='best')
2024-10-02 11:51:49,690:INFO:create_model() successfully completed......................................
2024-10-02 11:51:49,729:INFO:SubProcess create_model() end ==================================
2024-10-02 11:51:49,729:INFO:Creating metrics dataframe
2024-10-02 11:51:49,730:INFO:Initializing SVM - Linear Kernel
2024-10-02 11:51:49,730:INFO:Total runtime is 0.009855735301971437 minutes
2024-10-02 11:51:49,730:INFO:SubProcess create_model() called ==================================
2024-10-02 11:51:49,730:INFO:Initializing create_model()
2024-10-02 11:51:49,730:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171ed40d0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x171ed79a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:51:49,730:INFO:Checking exceptions
2024-10-02 11:51:49,730:INFO:Importing libraries
2024-10-02 11:51:49,730:INFO:Copying training dataset
2024-10-02 11:51:49,732:INFO:Defining folds
2024-10-02 11:51:49,732:INFO:Declaring metric variables
2024-10-02 11:51:49,732:INFO:Importing untrained model
2024-10-02 11:51:49,732:INFO:SVM - Linear Kernel Imported successfully
2024-10-02 11:51:49,732:INFO:Starting cross validation
2024-10-02 11:51:49,732:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:51:49,776:INFO:Calculating mean and std
2024-10-02 11:51:49,776:INFO:Creating metrics dataframe
2024-10-02 11:51:49,777:INFO:Uploading results into container
2024-10-02 11:51:49,777:INFO:Uploading model into container now
2024-10-02 11:51:49,777:INFO:_master_model_container: 5
2024-10-02 11:51:49,777:INFO:_display_container: 2
2024-10-02 11:51:49,777:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2574, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-10-02 11:51:49,778:INFO:create_model() successfully completed......................................
2024-10-02 11:51:49,818:INFO:SubProcess create_model() end ==================================
2024-10-02 11:51:49,818:INFO:Creating metrics dataframe
2024-10-02 11:51:49,819:INFO:Initializing Ridge Classifier
2024-10-02 11:51:49,819:INFO:Total runtime is 0.011335949103037517 minutes
2024-10-02 11:51:49,819:INFO:SubProcess create_model() called ==================================
2024-10-02 11:51:49,819:INFO:Initializing create_model()
2024-10-02 11:51:49,819:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171ed40d0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x171ed79a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:51:49,819:INFO:Checking exceptions
2024-10-02 11:51:49,819:INFO:Importing libraries
2024-10-02 11:51:49,819:INFO:Copying training dataset
2024-10-02 11:51:49,820:INFO:Defining folds
2024-10-02 11:51:49,820:INFO:Declaring metric variables
2024-10-02 11:51:49,820:INFO:Importing untrained model
2024-10-02 11:51:49,821:INFO:Ridge Classifier Imported successfully
2024-10-02 11:51:49,821:INFO:Starting cross validation
2024-10-02 11:51:49,821:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:51:49,860:INFO:Calculating mean and std
2024-10-02 11:51:49,860:INFO:Creating metrics dataframe
2024-10-02 11:51:49,861:INFO:Uploading results into container
2024-10-02 11:51:49,861:INFO:Uploading model into container now
2024-10-02 11:51:49,862:INFO:_master_model_container: 6
2024-10-02 11:51:49,862:INFO:_display_container: 2
2024-10-02 11:51:49,862:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2574, solver='auto',
                tol=0.0001)
2024-10-02 11:51:49,862:INFO:create_model() successfully completed......................................
2024-10-02 11:51:49,899:INFO:SubProcess create_model() end ==================================
2024-10-02 11:51:49,899:INFO:Creating metrics dataframe
2024-10-02 11:51:49,900:INFO:Initializing Random Forest Classifier
2024-10-02 11:51:49,900:INFO:Total runtime is 0.012688601016998292 minutes
2024-10-02 11:51:49,900:INFO:SubProcess create_model() called ==================================
2024-10-02 11:51:49,900:INFO:Initializing create_model()
2024-10-02 11:51:49,900:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171ed40d0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x171ed79a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:51:49,900:INFO:Checking exceptions
2024-10-02 11:51:49,900:INFO:Importing libraries
2024-10-02 11:51:49,900:INFO:Copying training dataset
2024-10-02 11:51:49,902:INFO:Defining folds
2024-10-02 11:51:49,902:INFO:Declaring metric variables
2024-10-02 11:51:49,902:INFO:Importing untrained model
2024-10-02 11:51:49,902:INFO:Random Forest Classifier Imported successfully
2024-10-02 11:51:49,902:INFO:Starting cross validation
2024-10-02 11:51:49,902:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:51:50,196:INFO:Calculating mean and std
2024-10-02 11:51:50,196:INFO:Creating metrics dataframe
2024-10-02 11:51:50,197:INFO:Uploading results into container
2024-10-02 11:51:50,197:INFO:Uploading model into container now
2024-10-02 11:51:50,197:INFO:_master_model_container: 7
2024-10-02 11:51:50,197:INFO:_display_container: 2
2024-10-02 11:51:50,198:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2574, verbose=0,
                       warm_start=False)
2024-10-02 11:51:50,198:INFO:create_model() successfully completed......................................
2024-10-02 11:51:50,237:INFO:SubProcess create_model() end ==================================
2024-10-02 11:51:50,237:INFO:Creating metrics dataframe
2024-10-02 11:51:50,238:INFO:Initializing Quadratic Discriminant Analysis
2024-10-02 11:51:50,238:INFO:Total runtime is 0.018323334058125813 minutes
2024-10-02 11:51:50,238:INFO:SubProcess create_model() called ==================================
2024-10-02 11:51:50,238:INFO:Initializing create_model()
2024-10-02 11:51:50,238:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171ed40d0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x171ed79a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:51:50,238:INFO:Checking exceptions
2024-10-02 11:51:50,238:INFO:Importing libraries
2024-10-02 11:51:50,238:INFO:Copying training dataset
2024-10-02 11:51:50,240:INFO:Defining folds
2024-10-02 11:51:50,240:INFO:Declaring metric variables
2024-10-02 11:51:50,240:INFO:Importing untrained model
2024-10-02 11:51:50,240:INFO:Quadratic Discriminant Analysis Imported successfully
2024-10-02 11:51:50,240:INFO:Starting cross validation
2024-10-02 11:51:50,240:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:51:50,279:INFO:Calculating mean and std
2024-10-02 11:51:50,279:INFO:Creating metrics dataframe
2024-10-02 11:51:50,280:INFO:Uploading results into container
2024-10-02 11:51:50,280:INFO:Uploading model into container now
2024-10-02 11:51:50,280:INFO:_master_model_container: 8
2024-10-02 11:51:50,280:INFO:_display_container: 2
2024-10-02 11:51:50,280:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-10-02 11:51:50,280:INFO:create_model() successfully completed......................................
2024-10-02 11:51:50,320:INFO:SubProcess create_model() end ==================================
2024-10-02 11:51:50,320:INFO:Creating metrics dataframe
2024-10-02 11:51:50,321:INFO:Initializing Ada Boost Classifier
2024-10-02 11:51:50,321:INFO:Total runtime is 0.019713799158732098 minutes
2024-10-02 11:51:50,321:INFO:SubProcess create_model() called ==================================
2024-10-02 11:51:50,322:INFO:Initializing create_model()
2024-10-02 11:51:50,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171ed40d0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x171ed79a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:51:50,322:INFO:Checking exceptions
2024-10-02 11:51:50,322:INFO:Importing libraries
2024-10-02 11:51:50,322:INFO:Copying training dataset
2024-10-02 11:51:50,323:INFO:Defining folds
2024-10-02 11:51:50,323:INFO:Declaring metric variables
2024-10-02 11:51:50,323:INFO:Importing untrained model
2024-10-02 11:51:50,323:INFO:Ada Boost Classifier Imported successfully
2024-10-02 11:51:50,323:INFO:Starting cross validation
2024-10-02 11:51:50,324:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:51:50,331:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:51:50,337:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:51:50,338:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:51:50,339:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:51:50,340:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:51:50,346:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:51:50,352:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:51:50,357:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:51:50,402:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:51:50,408:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:51:50,458:INFO:Calculating mean and std
2024-10-02 11:51:50,458:INFO:Creating metrics dataframe
2024-10-02 11:51:50,459:INFO:Uploading results into container
2024-10-02 11:51:50,459:INFO:Uploading model into container now
2024-10-02 11:51:50,459:INFO:_master_model_container: 9
2024-10-02 11:51:50,459:INFO:_display_container: 2
2024-10-02 11:51:50,459:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2574)
2024-10-02 11:51:50,459:INFO:create_model() successfully completed......................................
2024-10-02 11:51:50,501:INFO:SubProcess create_model() end ==================================
2024-10-02 11:51:50,501:INFO:Creating metrics dataframe
2024-10-02 11:51:50,502:INFO:Initializing Gradient Boosting Classifier
2024-10-02 11:51:50,502:INFO:Total runtime is 0.022726452350616457 minutes
2024-10-02 11:51:50,502:INFO:SubProcess create_model() called ==================================
2024-10-02 11:51:50,502:INFO:Initializing create_model()
2024-10-02 11:51:50,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171ed40d0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x171ed79a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:51:50,502:INFO:Checking exceptions
2024-10-02 11:51:50,502:INFO:Importing libraries
2024-10-02 11:51:50,502:INFO:Copying training dataset
2024-10-02 11:51:50,504:INFO:Defining folds
2024-10-02 11:51:50,504:INFO:Declaring metric variables
2024-10-02 11:51:50,504:INFO:Importing untrained model
2024-10-02 11:51:50,504:INFO:Gradient Boosting Classifier Imported successfully
2024-10-02 11:51:50,504:INFO:Starting cross validation
2024-10-02 11:51:50,505:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:51:50,722:INFO:Calculating mean and std
2024-10-02 11:51:50,723:INFO:Creating metrics dataframe
2024-10-02 11:51:50,723:INFO:Uploading results into container
2024-10-02 11:51:50,724:INFO:Uploading model into container now
2024-10-02 11:51:50,724:INFO:_master_model_container: 10
2024-10-02 11:51:50,724:INFO:_display_container: 2
2024-10-02 11:51:50,724:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2574, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-10-02 11:51:50,724:INFO:create_model() successfully completed......................................
2024-10-02 11:51:50,763:INFO:SubProcess create_model() end ==================================
2024-10-02 11:51:50,763:INFO:Creating metrics dataframe
2024-10-02 11:51:50,764:INFO:Initializing Linear Discriminant Analysis
2024-10-02 11:51:50,764:INFO:Total runtime is 0.027088069915771486 minutes
2024-10-02 11:51:50,764:INFO:SubProcess create_model() called ==================================
2024-10-02 11:51:50,764:INFO:Initializing create_model()
2024-10-02 11:51:50,764:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171ed40d0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x171ed79a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:51:50,764:INFO:Checking exceptions
2024-10-02 11:51:50,764:INFO:Importing libraries
2024-10-02 11:51:50,764:INFO:Copying training dataset
2024-10-02 11:51:50,766:INFO:Defining folds
2024-10-02 11:51:50,766:INFO:Declaring metric variables
2024-10-02 11:51:50,766:INFO:Importing untrained model
2024-10-02 11:51:50,766:INFO:Linear Discriminant Analysis Imported successfully
2024-10-02 11:51:50,766:INFO:Starting cross validation
2024-10-02 11:51:50,766:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:51:50,806:INFO:Calculating mean and std
2024-10-02 11:51:50,806:INFO:Creating metrics dataframe
2024-10-02 11:51:50,807:INFO:Uploading results into container
2024-10-02 11:51:50,807:INFO:Uploading model into container now
2024-10-02 11:51:50,807:INFO:_master_model_container: 11
2024-10-02 11:51:50,807:INFO:_display_container: 2
2024-10-02 11:51:50,808:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-10-02 11:51:50,808:INFO:create_model() successfully completed......................................
2024-10-02 11:51:50,847:INFO:SubProcess create_model() end ==================================
2024-10-02 11:51:50,847:INFO:Creating metrics dataframe
2024-10-02 11:51:50,848:INFO:Initializing Extra Trees Classifier
2024-10-02 11:51:50,848:INFO:Total runtime is 0.028488500912984212 minutes
2024-10-02 11:51:50,848:INFO:SubProcess create_model() called ==================================
2024-10-02 11:51:50,848:INFO:Initializing create_model()
2024-10-02 11:51:50,848:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171ed40d0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x171ed79a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:51:50,848:INFO:Checking exceptions
2024-10-02 11:51:50,848:INFO:Importing libraries
2024-10-02 11:51:50,848:INFO:Copying training dataset
2024-10-02 11:51:50,850:INFO:Defining folds
2024-10-02 11:51:50,850:INFO:Declaring metric variables
2024-10-02 11:51:50,850:INFO:Importing untrained model
2024-10-02 11:51:50,850:INFO:Extra Trees Classifier Imported successfully
2024-10-02 11:51:50,850:INFO:Starting cross validation
2024-10-02 11:51:50,850:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:51:51,087:INFO:Calculating mean and std
2024-10-02 11:51:51,087:INFO:Creating metrics dataframe
2024-10-02 11:51:51,088:INFO:Uploading results into container
2024-10-02 11:51:51,088:INFO:Uploading model into container now
2024-10-02 11:51:51,088:INFO:_master_model_container: 12
2024-10-02 11:51:51,088:INFO:_display_container: 2
2024-10-02 11:51:51,088:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=2574, verbose=0,
                     warm_start=False)
2024-10-02 11:51:51,088:INFO:create_model() successfully completed......................................
2024-10-02 11:51:51,127:INFO:SubProcess create_model() end ==================================
2024-10-02 11:51:51,127:INFO:Creating metrics dataframe
2024-10-02 11:51:51,128:INFO:Initializing Light Gradient Boosting Machine
2024-10-02 11:51:51,128:INFO:Total runtime is 0.03316160043080648 minutes
2024-10-02 11:51:51,128:INFO:SubProcess create_model() called ==================================
2024-10-02 11:51:51,128:INFO:Initializing create_model()
2024-10-02 11:51:51,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171ed40d0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x171ed79a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:51:51,128:INFO:Checking exceptions
2024-10-02 11:51:51,128:INFO:Importing libraries
2024-10-02 11:51:51,128:INFO:Copying training dataset
2024-10-02 11:51:51,130:INFO:Defining folds
2024-10-02 11:51:51,130:INFO:Declaring metric variables
2024-10-02 11:51:51,130:INFO:Importing untrained model
2024-10-02 11:51:51,130:INFO:Light Gradient Boosting Machine Imported successfully
2024-10-02 11:51:51,130:INFO:Starting cross validation
2024-10-02 11:51:51,131:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:51:53,070:INFO:Calculating mean and std
2024-10-02 11:51:53,070:INFO:Creating metrics dataframe
2024-10-02 11:51:53,071:INFO:Uploading results into container
2024-10-02 11:51:53,071:INFO:Uploading model into container now
2024-10-02 11:51:53,071:INFO:_master_model_container: 13
2024-10-02 11:51:53,071:INFO:_display_container: 2
2024-10-02 11:51:53,072:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2574, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-10-02 11:51:53,072:INFO:create_model() successfully completed......................................
2024-10-02 11:51:53,111:INFO:SubProcess create_model() end ==================================
2024-10-02 11:51:53,111:INFO:Creating metrics dataframe
2024-10-02 11:51:53,112:INFO:Initializing Dummy Classifier
2024-10-02 11:51:53,112:INFO:Total runtime is 0.06622554858525595 minutes
2024-10-02 11:51:53,112:INFO:SubProcess create_model() called ==================================
2024-10-02 11:51:53,112:INFO:Initializing create_model()
2024-10-02 11:51:53,112:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171ed40d0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x171ed79a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:51:53,112:INFO:Checking exceptions
2024-10-02 11:51:53,112:INFO:Importing libraries
2024-10-02 11:51:53,112:INFO:Copying training dataset
2024-10-02 11:51:53,114:INFO:Defining folds
2024-10-02 11:51:53,114:INFO:Declaring metric variables
2024-10-02 11:51:53,114:INFO:Importing untrained model
2024-10-02 11:51:53,114:INFO:Dummy Classifier Imported successfully
2024-10-02 11:51:53,114:INFO:Starting cross validation
2024-10-02 11:51:53,114:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:51:53,152:INFO:Calculating mean and std
2024-10-02 11:51:53,152:INFO:Creating metrics dataframe
2024-10-02 11:51:53,153:INFO:Uploading results into container
2024-10-02 11:51:53,153:INFO:Uploading model into container now
2024-10-02 11:51:53,153:INFO:_master_model_container: 14
2024-10-02 11:51:53,153:INFO:_display_container: 2
2024-10-02 11:51:53,153:INFO:DummyClassifier(constant=None, random_state=2574, strategy='prior')
2024-10-02 11:51:53,153:INFO:create_model() successfully completed......................................
2024-10-02 11:51:53,193:INFO:SubProcess create_model() end ==================================
2024-10-02 11:51:53,194:INFO:Creating metrics dataframe
2024-10-02 11:51:53,195:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-10-02 11:51:53,196:INFO:Initializing create_model()
2024-10-02 11:51:53,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171ed40d0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2574, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:51:53,196:INFO:Checking exceptions
2024-10-02 11:51:53,196:INFO:Importing libraries
2024-10-02 11:51:53,196:INFO:Copying training dataset
2024-10-02 11:51:53,198:INFO:Defining folds
2024-10-02 11:51:53,198:INFO:Declaring metric variables
2024-10-02 11:51:53,198:INFO:Importing untrained model
2024-10-02 11:51:53,198:INFO:Declaring custom model
2024-10-02 11:51:53,198:INFO:Random Forest Classifier Imported successfully
2024-10-02 11:51:53,199:INFO:Cross validation set to False
2024-10-02 11:51:53,199:INFO:Fitting Model
2024-10-02 11:51:53,274:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2574, verbose=0,
                       warm_start=False)
2024-10-02 11:51:53,274:INFO:create_model() successfully completed......................................
2024-10-02 11:51:53,317:INFO:_master_model_container: 14
2024-10-02 11:51:53,317:INFO:_display_container: 2
2024-10-02 11:51:53,317:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2574, verbose=0,
                       warm_start=False)
2024-10-02 11:51:53,317:INFO:compare_models() successfully completed......................................
2024-10-02 11:51:53,320:INFO:Initializing save_model()
2024-10-02 11:51:53,320:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=2574, verbose=0,
                       warm_start=False), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/tx/71pw4d8d2l95h2ffhyf9cq340000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'sex', 'cp', 'trestbps',
                                             'chol', 'fbs', 'restecg',
                                             'thalach', 'exang', 'oldpeak',
                                             'slope', 'ca', 'thal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-10-02 11:51:53,321:INFO:Adding model into prep_pipe
2024-10-02 11:51:53,364:INFO:best_model.pkl saved in current working directory
2024-10-02 11:51:53,366:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'sex', 'cp', 'trestbps',
                                             'chol', 'fbs', 'restecg',
                                             'thalach', 'exang', 'oldpeak',
                                             'slope', 'ca', 'thal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categ...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        monotonic_cst=None, n_estimators=100,
                                        n_jobs=-1, oob_score=False,
                                        random_state=2574, verbose=0,
                                        warm_start=False))],
         verbose=False)
2024-10-02 11:51:53,366:INFO:save_model() successfully completed......................................
2024-10-02 11:58:00,006:INFO:PyCaret ClassificationExperiment
2024-10-02 11:58:00,007:INFO:Logging name: clf-default-name
2024-10-02 11:58:00,007:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-10-02 11:58:00,008:INFO:version 3.3.2
2024-10-02 11:58:00,008:INFO:Initializing setup()
2024-10-02 11:58:00,008:INFO:self.USI: 3828
2024-10-02 11:58:00,008:INFO:self._variable_keys: {'y_train', 'logging_param', 'fold_shuffle_param', '_ml_usecase', 'n_jobs_param', 'fold_generator', 'idx', 'data', 'pipeline', 'exp_name_log', 'X', 'gpu_param', 'html_param', 'gpu_n_jobs_param', 'target_param', 'y_test', 'fix_imbalance', 'X_test', 'fold_groups_param', 'log_plots_param', 'exp_id', 'y', 'X_train', '_available_plots', 'USI', 'memory', 'is_multiclass', 'seed'}
2024-10-02 11:58:00,008:INFO:Checking environment
2024-10-02 11:58:00,008:INFO:python_version: 3.10.9
2024-10-02 11:58:00,008:INFO:python_build: ('v3.10.9:1dd9be6584', 'Dec  6 2022 14:37:36')
2024-10-02 11:58:00,008:INFO:machine: arm64
2024-10-02 11:58:00,008:INFO:platform: macOS-13.5.1-arm64-arm-64bit
2024-10-02 11:58:00,009:INFO:Memory: svmem(total=8589934592, available=1541832704, percent=82.1, used=3027189760, free=102596608, active=1458503680, inactive=1429143552, wired=1568686080)
2024-10-02 11:58:00,009:INFO:Physical Core: 8
2024-10-02 11:58:00,009:INFO:Logical Core: 8
2024-10-02 11:58:00,009:INFO:Checking libraries
2024-10-02 11:58:00,009:INFO:System:
2024-10-02 11:58:00,009:INFO:    python: 3.10.9 (v3.10.9:1dd9be6584, Dec  6 2022, 14:37:36) [Clang 13.0.0 (clang-1300.0.29.30)]
2024-10-02 11:58:00,009:INFO:executable: /Users/pratek/test1/Report/.venv/bin/python
2024-10-02 11:58:00,009:INFO:   machine: macOS-13.5.1-arm64-arm-64bit
2024-10-02 11:58:00,009:INFO:PyCaret required dependencies:
2024-10-02 11:58:00,009:INFO:                 pip: 24.2
2024-10-02 11:58:00,009:INFO:          setuptools: 68.2.0
2024-10-02 11:58:00,009:INFO:             pycaret: 3.3.2
2024-10-02 11:58:00,009:INFO:             IPython: 8.27.0
2024-10-02 11:58:00,009:INFO:          ipywidgets: 8.1.5
2024-10-02 11:58:00,009:INFO:                tqdm: 4.66.5
2024-10-02 11:58:00,009:INFO:               numpy: 1.26.4
2024-10-02 11:58:00,009:INFO:              pandas: 2.1.4
2024-10-02 11:58:00,010:INFO:              jinja2: 3.1.4
2024-10-02 11:58:00,010:INFO:               scipy: 1.11.4
2024-10-02 11:58:00,010:INFO:              joblib: 1.3.2
2024-10-02 11:58:00,010:INFO:             sklearn: 1.4.2
2024-10-02 11:58:00,010:INFO:                pyod: 2.0.2
2024-10-02 11:58:00,010:INFO:            imblearn: 0.12.3
2024-10-02 11:58:00,010:INFO:   category_encoders: 2.6.4
2024-10-02 11:58:00,010:INFO:            lightgbm: 4.5.0
2024-10-02 11:58:00,010:INFO:               numba: 0.60.0
2024-10-02 11:58:00,010:INFO:            requests: 2.32.3
2024-10-02 11:58:00,010:INFO:          matplotlib: 3.7.5
2024-10-02 11:58:00,010:INFO:          scikitplot: 0.3.7
2024-10-02 11:58:00,010:INFO:         yellowbrick: 1.5
2024-10-02 11:58:00,010:INFO:              plotly: 5.24.1
2024-10-02 11:58:00,010:INFO:    plotly-resampler: Not installed
2024-10-02 11:58:00,010:INFO:             kaleido: 0.2.1
2024-10-02 11:58:00,010:INFO:           schemdraw: 0.15
2024-10-02 11:58:00,010:INFO:         statsmodels: 0.14.3
2024-10-02 11:58:00,010:INFO:              sktime: 0.26.0
2024-10-02 11:58:00,010:INFO:               tbats: 1.1.3
2024-10-02 11:58:00,010:INFO:            pmdarima: 2.0.4
2024-10-02 11:58:00,010:INFO:              psutil: 6.0.0
2024-10-02 11:58:00,010:INFO:          markupsafe: 2.1.5
2024-10-02 11:58:00,010:INFO:             pickle5: Not installed
2024-10-02 11:58:00,010:INFO:         cloudpickle: 3.0.0
2024-10-02 11:58:00,010:INFO:         deprecation: 2.1.0
2024-10-02 11:58:00,010:INFO:              xxhash: 3.5.0
2024-10-02 11:58:00,010:INFO:           wurlitzer: 3.1.1
2024-10-02 11:58:00,010:INFO:PyCaret optional dependencies:
2024-10-02 11:58:00,010:INFO:                shap: Not installed
2024-10-02 11:58:00,010:INFO:           interpret: Not installed
2024-10-02 11:58:00,010:INFO:                umap: Not installed
2024-10-02 11:58:00,010:INFO:     ydata_profiling: 4.10.0
2024-10-02 11:58:00,010:INFO:  explainerdashboard: Not installed
2024-10-02 11:58:00,010:INFO:             autoviz: Not installed
2024-10-02 11:58:00,010:INFO:           fairlearn: Not installed
2024-10-02 11:58:00,011:INFO:          deepchecks: Not installed
2024-10-02 11:58:00,011:INFO:             xgboost: Not installed
2024-10-02 11:58:00,011:INFO:            catboost: Not installed
2024-10-02 11:58:00,011:INFO:              kmodes: Not installed
2024-10-02 11:58:00,011:INFO:             mlxtend: Not installed
2024-10-02 11:58:00,011:INFO:       statsforecast: Not installed
2024-10-02 11:58:00,011:INFO:        tune_sklearn: Not installed
2024-10-02 11:58:00,011:INFO:                 ray: Not installed
2024-10-02 11:58:00,011:INFO:            hyperopt: Not installed
2024-10-02 11:58:00,011:INFO:              optuna: Not installed
2024-10-02 11:58:00,011:INFO:               skopt: Not installed
2024-10-02 11:58:00,011:INFO:              mlflow: Not installed
2024-10-02 11:58:00,011:INFO:              gradio: Not installed
2024-10-02 11:58:00,011:INFO:             fastapi: Not installed
2024-10-02 11:58:00,011:INFO:             uvicorn: Not installed
2024-10-02 11:58:00,011:INFO:              m2cgen: Not installed
2024-10-02 11:58:00,011:INFO:           evidently: Not installed
2024-10-02 11:58:00,011:INFO:               fugue: Not installed
2024-10-02 11:58:00,011:INFO:           streamlit: 1.39.0
2024-10-02 11:58:00,011:INFO:             prophet: Not installed
2024-10-02 11:58:00,011:INFO:None
2024-10-02 11:58:00,011:INFO:Set up data.
2024-10-02 11:58:00,023:INFO:Set up folding strategy.
2024-10-02 11:58:00,023:INFO:Set up train/test split.
2024-10-02 11:58:00,030:INFO:Set up index.
2024-10-02 11:58:00,031:INFO:Assigning column types.
2024-10-02 11:58:00,033:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-10-02 11:58:00,057:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-02 11:58:00,058:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-02 11:58:00,071:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:58:00,071:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:58:00,089:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-10-02 11:58:00,089:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-02 11:58:00,100:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:58:00,100:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:58:00,100:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-10-02 11:58:00,118:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-02 11:58:00,129:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:58:00,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:58:00,146:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-10-02 11:58:00,157:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:58:00,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:58:00,157:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-10-02 11:58:00,186:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:58:00,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:58:00,214:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:58:00,214:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:58:00,214:INFO:Preparing preprocessing pipeline...
2024-10-02 11:58:00,216:INFO:Set up simple imputation.
2024-10-02 11:58:00,225:INFO:Finished creating preprocessing pipeline.
2024-10-02 11:58:00,226:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/tx/71pw4d8d2l95h2ffhyf9cq340000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'sex', 'cp', 'trestbps',
                                             'chol', 'fbs', 'restecg',
                                             'thalach', 'exang', 'oldpeak',
                                             'slope', 'ca', 'thal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2024-10-02 11:58:00,226:INFO:Creating final display dataframe.
2024-10-02 11:58:00,253:INFO:Setup _display_container:                     Description             Value
0                    Session id              8220
1                        Target            target
2                   Target type            Binary
3           Original data shape        (1025, 14)
4        Transformed data shape        (1025, 14)
5   Transformed train set shape         (717, 14)
6    Transformed test set shape         (308, 14)
7              Numeric features                13
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              3828
2024-10-02 11:58:00,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:58:00,283:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:58:00,312:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:58:00,312:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-10-02 11:58:00,312:INFO:setup() successfully completed in 0.31s...............
2024-10-02 11:58:00,318:INFO:Initializing compare_models()
2024-10-02 11:58:00,318:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171e32770>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x171e32770>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-10-02 11:58:00,318:INFO:Checking exceptions
2024-10-02 11:58:00,319:INFO:Preparing display monitor
2024-10-02 11:58:00,321:INFO:Initializing Logistic Regression
2024-10-02 11:58:00,321:INFO:Total runtime is 5.006790161132813e-07 minutes
2024-10-02 11:58:00,321:INFO:SubProcess create_model() called ==================================
2024-10-02 11:58:00,321:INFO:Initializing create_model()
2024-10-02 11:58:00,321:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171e32770>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1721602b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:58:00,321:INFO:Checking exceptions
2024-10-02 11:58:00,321:INFO:Importing libraries
2024-10-02 11:58:00,321:INFO:Copying training dataset
2024-10-02 11:58:00,322:INFO:Defining folds
2024-10-02 11:58:00,322:INFO:Declaring metric variables
2024-10-02 11:58:00,322:INFO:Importing untrained model
2024-10-02 11:58:00,323:INFO:Logistic Regression Imported successfully
2024-10-02 11:58:00,323:INFO:Starting cross validation
2024-10-02 11:58:00,323:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:58:00,483:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-10-02 11:58:02,161:INFO:Calculating mean and std
2024-10-02 11:58:02,162:INFO:Creating metrics dataframe
2024-10-02 11:58:02,165:INFO:Uploading results into container
2024-10-02 11:58:02,165:INFO:Uploading model into container now
2024-10-02 11:58:02,166:INFO:_master_model_container: 1
2024-10-02 11:58:02,166:INFO:_display_container: 2
2024-10-02 11:58:02,167:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8220, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-10-02 11:58:02,167:INFO:create_model() successfully completed......................................
2024-10-02 11:58:02,226:INFO:SubProcess create_model() end ==================================
2024-10-02 11:58:02,226:INFO:Creating metrics dataframe
2024-10-02 11:58:02,227:INFO:Initializing K Neighbors Classifier
2024-10-02 11:58:02,227:INFO:Total runtime is 0.03176710208257039 minutes
2024-10-02 11:58:02,227:INFO:SubProcess create_model() called ==================================
2024-10-02 11:58:02,227:INFO:Initializing create_model()
2024-10-02 11:58:02,227:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171e32770>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1721602b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:58:02,227:INFO:Checking exceptions
2024-10-02 11:58:02,227:INFO:Importing libraries
2024-10-02 11:58:02,227:INFO:Copying training dataset
2024-10-02 11:58:02,228:INFO:Defining folds
2024-10-02 11:58:02,228:INFO:Declaring metric variables
2024-10-02 11:58:02,229:INFO:Importing untrained model
2024-10-02 11:58:02,229:INFO:K Neighbors Classifier Imported successfully
2024-10-02 11:58:02,229:INFO:Starting cross validation
2024-10-02 11:58:02,229:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:58:03,000:INFO:Calculating mean and std
2024-10-02 11:58:03,001:INFO:Creating metrics dataframe
2024-10-02 11:58:03,002:INFO:Uploading results into container
2024-10-02 11:58:03,003:INFO:Uploading model into container now
2024-10-02 11:58:03,003:INFO:_master_model_container: 2
2024-10-02 11:58:03,003:INFO:_display_container: 2
2024-10-02 11:58:03,003:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-10-02 11:58:03,003:INFO:create_model() successfully completed......................................
2024-10-02 11:58:03,049:INFO:SubProcess create_model() end ==================================
2024-10-02 11:58:03,050:INFO:Creating metrics dataframe
2024-10-02 11:58:03,051:INFO:Initializing Naive Bayes
2024-10-02 11:58:03,051:INFO:Total runtime is 0.04549953540166219 minutes
2024-10-02 11:58:03,051:INFO:SubProcess create_model() called ==================================
2024-10-02 11:58:03,051:INFO:Initializing create_model()
2024-10-02 11:58:03,051:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171e32770>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1721602b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:58:03,051:INFO:Checking exceptions
2024-10-02 11:58:03,051:INFO:Importing libraries
2024-10-02 11:58:03,051:INFO:Copying training dataset
2024-10-02 11:58:03,052:INFO:Defining folds
2024-10-02 11:58:03,052:INFO:Declaring metric variables
2024-10-02 11:58:03,052:INFO:Importing untrained model
2024-10-02 11:58:03,053:INFO:Naive Bayes Imported successfully
2024-10-02 11:58:03,053:INFO:Starting cross validation
2024-10-02 11:58:03,053:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:58:03,103:INFO:Calculating mean and std
2024-10-02 11:58:03,103:INFO:Creating metrics dataframe
2024-10-02 11:58:03,104:INFO:Uploading results into container
2024-10-02 11:58:03,104:INFO:Uploading model into container now
2024-10-02 11:58:03,104:INFO:_master_model_container: 3
2024-10-02 11:58:03,104:INFO:_display_container: 2
2024-10-02 11:58:03,105:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-10-02 11:58:03,105:INFO:create_model() successfully completed......................................
2024-10-02 11:58:03,142:INFO:SubProcess create_model() end ==================================
2024-10-02 11:58:03,142:INFO:Creating metrics dataframe
2024-10-02 11:58:03,143:INFO:Initializing Decision Tree Classifier
2024-10-02 11:58:03,143:INFO:Total runtime is 0.04703387022018433 minutes
2024-10-02 11:58:03,143:INFO:SubProcess create_model() called ==================================
2024-10-02 11:58:03,143:INFO:Initializing create_model()
2024-10-02 11:58:03,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171e32770>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1721602b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:58:03,143:INFO:Checking exceptions
2024-10-02 11:58:03,143:INFO:Importing libraries
2024-10-02 11:58:03,143:INFO:Copying training dataset
2024-10-02 11:58:03,144:INFO:Defining folds
2024-10-02 11:58:03,144:INFO:Declaring metric variables
2024-10-02 11:58:03,144:INFO:Importing untrained model
2024-10-02 11:58:03,145:INFO:Decision Tree Classifier Imported successfully
2024-10-02 11:58:03,145:INFO:Starting cross validation
2024-10-02 11:58:03,145:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:58:03,186:INFO:Calculating mean and std
2024-10-02 11:58:03,186:INFO:Creating metrics dataframe
2024-10-02 11:58:03,187:INFO:Uploading results into container
2024-10-02 11:58:03,187:INFO:Uploading model into container now
2024-10-02 11:58:03,187:INFO:_master_model_container: 4
2024-10-02 11:58:03,187:INFO:_display_container: 2
2024-10-02 11:58:03,187:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8220, splitter='best')
2024-10-02 11:58:03,187:INFO:create_model() successfully completed......................................
2024-10-02 11:58:03,224:INFO:SubProcess create_model() end ==================================
2024-10-02 11:58:03,224:INFO:Creating metrics dataframe
2024-10-02 11:58:03,225:INFO:Initializing SVM - Linear Kernel
2024-10-02 11:58:03,225:INFO:Total runtime is 0.04840388298034668 minutes
2024-10-02 11:58:03,225:INFO:SubProcess create_model() called ==================================
2024-10-02 11:58:03,225:INFO:Initializing create_model()
2024-10-02 11:58:03,225:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171e32770>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1721602b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:58:03,225:INFO:Checking exceptions
2024-10-02 11:58:03,225:INFO:Importing libraries
2024-10-02 11:58:03,225:INFO:Copying training dataset
2024-10-02 11:58:03,227:INFO:Defining folds
2024-10-02 11:58:03,227:INFO:Declaring metric variables
2024-10-02 11:58:03,227:INFO:Importing untrained model
2024-10-02 11:58:03,227:INFO:SVM - Linear Kernel Imported successfully
2024-10-02 11:58:03,227:INFO:Starting cross validation
2024-10-02 11:58:03,227:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:58:03,261:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-10-02 11:58:03,268:INFO:Calculating mean and std
2024-10-02 11:58:03,268:INFO:Creating metrics dataframe
2024-10-02 11:58:03,269:INFO:Uploading results into container
2024-10-02 11:58:03,269:INFO:Uploading model into container now
2024-10-02 11:58:03,269:INFO:_master_model_container: 5
2024-10-02 11:58:03,269:INFO:_display_container: 2
2024-10-02 11:58:03,269:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8220, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-10-02 11:58:03,269:INFO:create_model() successfully completed......................................
2024-10-02 11:58:03,306:INFO:SubProcess create_model() end ==================================
2024-10-02 11:58:03,306:INFO:Creating metrics dataframe
2024-10-02 11:58:03,307:INFO:Initializing Ridge Classifier
2024-10-02 11:58:03,307:INFO:Total runtime is 0.04976861874262492 minutes
2024-10-02 11:58:03,307:INFO:SubProcess create_model() called ==================================
2024-10-02 11:58:03,307:INFO:Initializing create_model()
2024-10-02 11:58:03,307:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171e32770>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1721602b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:58:03,307:INFO:Checking exceptions
2024-10-02 11:58:03,307:INFO:Importing libraries
2024-10-02 11:58:03,307:INFO:Copying training dataset
2024-10-02 11:58:03,309:INFO:Defining folds
2024-10-02 11:58:03,309:INFO:Declaring metric variables
2024-10-02 11:58:03,309:INFO:Importing untrained model
2024-10-02 11:58:03,309:INFO:Ridge Classifier Imported successfully
2024-10-02 11:58:03,309:INFO:Starting cross validation
2024-10-02 11:58:03,309:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:58:03,349:INFO:Calculating mean and std
2024-10-02 11:58:03,350:INFO:Creating metrics dataframe
2024-10-02 11:58:03,350:INFO:Uploading results into container
2024-10-02 11:58:03,350:INFO:Uploading model into container now
2024-10-02 11:58:03,351:INFO:_master_model_container: 6
2024-10-02 11:58:03,351:INFO:_display_container: 2
2024-10-02 11:58:03,351:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8220, solver='auto',
                tol=0.0001)
2024-10-02 11:58:03,351:INFO:create_model() successfully completed......................................
2024-10-02 11:58:03,388:INFO:SubProcess create_model() end ==================================
2024-10-02 11:58:03,388:INFO:Creating metrics dataframe
2024-10-02 11:58:03,389:INFO:Initializing Random Forest Classifier
2024-10-02 11:58:03,389:INFO:Total runtime is 0.051139601071675624 minutes
2024-10-02 11:58:03,389:INFO:SubProcess create_model() called ==================================
2024-10-02 11:58:03,389:INFO:Initializing create_model()
2024-10-02 11:58:03,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171e32770>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1721602b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:58:03,389:INFO:Checking exceptions
2024-10-02 11:58:03,389:INFO:Importing libraries
2024-10-02 11:58:03,389:INFO:Copying training dataset
2024-10-02 11:58:03,391:INFO:Defining folds
2024-10-02 11:58:03,391:INFO:Declaring metric variables
2024-10-02 11:58:03,391:INFO:Importing untrained model
2024-10-02 11:58:03,391:INFO:Random Forest Classifier Imported successfully
2024-10-02 11:58:03,391:INFO:Starting cross validation
2024-10-02 11:58:03,391:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:58:03,680:INFO:Calculating mean and std
2024-10-02 11:58:03,681:INFO:Creating metrics dataframe
2024-10-02 11:58:03,681:INFO:Uploading results into container
2024-10-02 11:58:03,682:INFO:Uploading model into container now
2024-10-02 11:58:03,682:INFO:_master_model_container: 7
2024-10-02 11:58:03,682:INFO:_display_container: 2
2024-10-02 11:58:03,682:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8220, verbose=0,
                       warm_start=False)
2024-10-02 11:58:03,682:INFO:create_model() successfully completed......................................
2024-10-02 11:58:03,719:INFO:SubProcess create_model() end ==================================
2024-10-02 11:58:03,719:INFO:Creating metrics dataframe
2024-10-02 11:58:03,720:INFO:Initializing Quadratic Discriminant Analysis
2024-10-02 11:58:03,720:INFO:Total runtime is 0.056657870610555015 minutes
2024-10-02 11:58:03,720:INFO:SubProcess create_model() called ==================================
2024-10-02 11:58:03,720:INFO:Initializing create_model()
2024-10-02 11:58:03,720:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171e32770>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1721602b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:58:03,720:INFO:Checking exceptions
2024-10-02 11:58:03,721:INFO:Importing libraries
2024-10-02 11:58:03,721:INFO:Copying training dataset
2024-10-02 11:58:03,722:INFO:Defining folds
2024-10-02 11:58:03,722:INFO:Declaring metric variables
2024-10-02 11:58:03,722:INFO:Importing untrained model
2024-10-02 11:58:03,722:INFO:Quadratic Discriminant Analysis Imported successfully
2024-10-02 11:58:03,722:INFO:Starting cross validation
2024-10-02 11:58:03,722:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:58:03,761:INFO:Calculating mean and std
2024-10-02 11:58:03,761:INFO:Creating metrics dataframe
2024-10-02 11:58:03,762:INFO:Uploading results into container
2024-10-02 11:58:03,762:INFO:Uploading model into container now
2024-10-02 11:58:03,762:INFO:_master_model_container: 8
2024-10-02 11:58:03,762:INFO:_display_container: 2
2024-10-02 11:58:03,762:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-10-02 11:58:03,762:INFO:create_model() successfully completed......................................
2024-10-02 11:58:03,798:INFO:SubProcess create_model() end ==================================
2024-10-02 11:58:03,798:INFO:Creating metrics dataframe
2024-10-02 11:58:03,799:INFO:Initializing Ada Boost Classifier
2024-10-02 11:58:03,799:INFO:Total runtime is 0.05797326962153117 minutes
2024-10-02 11:58:03,799:INFO:SubProcess create_model() called ==================================
2024-10-02 11:58:03,799:INFO:Initializing create_model()
2024-10-02 11:58:03,799:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171e32770>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1721602b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:58:03,799:INFO:Checking exceptions
2024-10-02 11:58:03,799:INFO:Importing libraries
2024-10-02 11:58:03,799:INFO:Copying training dataset
2024-10-02 11:58:03,801:INFO:Defining folds
2024-10-02 11:58:03,801:INFO:Declaring metric variables
2024-10-02 11:58:03,801:INFO:Importing untrained model
2024-10-02 11:58:03,801:INFO:Ada Boost Classifier Imported successfully
2024-10-02 11:58:03,801:INFO:Starting cross validation
2024-10-02 11:58:03,801:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:58:03,810:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:58:03,813:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:58:03,816:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:58:03,817:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:58:03,824:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:58:03,825:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:58:03,831:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:58:03,850:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:58:03,872:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:58:03,876:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-10-02 11:58:03,930:INFO:Calculating mean and std
2024-10-02 11:58:03,931:INFO:Creating metrics dataframe
2024-10-02 11:58:03,931:INFO:Uploading results into container
2024-10-02 11:58:03,931:INFO:Uploading model into container now
2024-10-02 11:58:03,932:INFO:_master_model_container: 9
2024-10-02 11:58:03,932:INFO:_display_container: 2
2024-10-02 11:58:03,932:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8220)
2024-10-02 11:58:03,932:INFO:create_model() successfully completed......................................
2024-10-02 11:58:03,967:INFO:SubProcess create_model() end ==================================
2024-10-02 11:58:03,967:INFO:Creating metrics dataframe
2024-10-02 11:58:03,968:INFO:Initializing Gradient Boosting Classifier
2024-10-02 11:58:03,968:INFO:Total runtime is 0.060793904463450114 minutes
2024-10-02 11:58:03,968:INFO:SubProcess create_model() called ==================================
2024-10-02 11:58:03,969:INFO:Initializing create_model()
2024-10-02 11:58:03,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171e32770>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1721602b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:58:03,969:INFO:Checking exceptions
2024-10-02 11:58:03,969:INFO:Importing libraries
2024-10-02 11:58:03,969:INFO:Copying training dataset
2024-10-02 11:58:03,970:INFO:Defining folds
2024-10-02 11:58:03,970:INFO:Declaring metric variables
2024-10-02 11:58:03,970:INFO:Importing untrained model
2024-10-02 11:58:03,970:INFO:Gradient Boosting Classifier Imported successfully
2024-10-02 11:58:03,970:INFO:Starting cross validation
2024-10-02 11:58:03,971:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:58:04,173:INFO:Calculating mean and std
2024-10-02 11:58:04,173:INFO:Creating metrics dataframe
2024-10-02 11:58:04,174:INFO:Uploading results into container
2024-10-02 11:58:04,174:INFO:Uploading model into container now
2024-10-02 11:58:04,174:INFO:_master_model_container: 10
2024-10-02 11:58:04,174:INFO:_display_container: 2
2024-10-02 11:58:04,175:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8220, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-10-02 11:58:04,175:INFO:create_model() successfully completed......................................
2024-10-02 11:58:04,210:INFO:SubProcess create_model() end ==================================
2024-10-02 11:58:04,210:INFO:Creating metrics dataframe
2024-10-02 11:58:04,211:INFO:Initializing Linear Discriminant Analysis
2024-10-02 11:58:04,211:INFO:Total runtime is 0.06484271685282389 minutes
2024-10-02 11:58:04,211:INFO:SubProcess create_model() called ==================================
2024-10-02 11:58:04,211:INFO:Initializing create_model()
2024-10-02 11:58:04,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171e32770>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1721602b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:58:04,212:INFO:Checking exceptions
2024-10-02 11:58:04,212:INFO:Importing libraries
2024-10-02 11:58:04,212:INFO:Copying training dataset
2024-10-02 11:58:04,213:INFO:Defining folds
2024-10-02 11:58:04,213:INFO:Declaring metric variables
2024-10-02 11:58:04,213:INFO:Importing untrained model
2024-10-02 11:58:04,213:INFO:Linear Discriminant Analysis Imported successfully
2024-10-02 11:58:04,213:INFO:Starting cross validation
2024-10-02 11:58:04,214:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:58:04,252:INFO:Calculating mean and std
2024-10-02 11:58:04,253:INFO:Creating metrics dataframe
2024-10-02 11:58:04,253:INFO:Uploading results into container
2024-10-02 11:58:04,254:INFO:Uploading model into container now
2024-10-02 11:58:04,254:INFO:_master_model_container: 11
2024-10-02 11:58:04,254:INFO:_display_container: 2
2024-10-02 11:58:04,254:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-10-02 11:58:04,254:INFO:create_model() successfully completed......................................
2024-10-02 11:58:04,290:INFO:SubProcess create_model() end ==================================
2024-10-02 11:58:04,290:INFO:Creating metrics dataframe
2024-10-02 11:58:04,291:INFO:Initializing Extra Trees Classifier
2024-10-02 11:58:04,291:INFO:Total runtime is 0.06617666482925415 minutes
2024-10-02 11:58:04,291:INFO:SubProcess create_model() called ==================================
2024-10-02 11:58:04,292:INFO:Initializing create_model()
2024-10-02 11:58:04,292:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171e32770>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1721602b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:58:04,292:INFO:Checking exceptions
2024-10-02 11:58:04,292:INFO:Importing libraries
2024-10-02 11:58:04,292:INFO:Copying training dataset
2024-10-02 11:58:04,293:INFO:Defining folds
2024-10-02 11:58:04,293:INFO:Declaring metric variables
2024-10-02 11:58:04,293:INFO:Importing untrained model
2024-10-02 11:58:04,293:INFO:Extra Trees Classifier Imported successfully
2024-10-02 11:58:04,293:INFO:Starting cross validation
2024-10-02 11:58:04,294:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:58:04,519:INFO:Calculating mean and std
2024-10-02 11:58:04,520:INFO:Creating metrics dataframe
2024-10-02 11:58:04,521:INFO:Uploading results into container
2024-10-02 11:58:04,521:INFO:Uploading model into container now
2024-10-02 11:58:04,521:INFO:_master_model_container: 12
2024-10-02 11:58:04,521:INFO:_display_container: 2
2024-10-02 11:58:04,521:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8220, verbose=0,
                     warm_start=False)
2024-10-02 11:58:04,521:INFO:create_model() successfully completed......................................
2024-10-02 11:58:04,559:INFO:SubProcess create_model() end ==================================
2024-10-02 11:58:04,559:INFO:Creating metrics dataframe
2024-10-02 11:58:04,560:INFO:Initializing Light Gradient Boosting Machine
2024-10-02 11:58:04,560:INFO:Total runtime is 0.07065606911977132 minutes
2024-10-02 11:58:04,560:INFO:SubProcess create_model() called ==================================
2024-10-02 11:58:04,560:INFO:Initializing create_model()
2024-10-02 11:58:04,560:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171e32770>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1721602b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:58:04,560:INFO:Checking exceptions
2024-10-02 11:58:04,560:INFO:Importing libraries
2024-10-02 11:58:04,560:INFO:Copying training dataset
2024-10-02 11:58:04,562:INFO:Defining folds
2024-10-02 11:58:04,562:INFO:Declaring metric variables
2024-10-02 11:58:04,562:INFO:Importing untrained model
2024-10-02 11:58:04,562:INFO:Light Gradient Boosting Machine Imported successfully
2024-10-02 11:58:04,562:INFO:Starting cross validation
2024-10-02 11:58:04,562:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:58:06,521:INFO:Calculating mean and std
2024-10-02 11:58:06,521:INFO:Creating metrics dataframe
2024-10-02 11:58:06,522:INFO:Uploading results into container
2024-10-02 11:58:06,522:INFO:Uploading model into container now
2024-10-02 11:58:06,522:INFO:_master_model_container: 13
2024-10-02 11:58:06,522:INFO:_display_container: 2
2024-10-02 11:58:06,523:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8220, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-10-02 11:58:06,523:INFO:create_model() successfully completed......................................
2024-10-02 11:58:06,560:INFO:SubProcess create_model() end ==================================
2024-10-02 11:58:06,560:INFO:Creating metrics dataframe
2024-10-02 11:58:06,561:INFO:Initializing Dummy Classifier
2024-10-02 11:58:06,561:INFO:Total runtime is 0.10400856733322143 minutes
2024-10-02 11:58:06,561:INFO:SubProcess create_model() called ==================================
2024-10-02 11:58:06,561:INFO:Initializing create_model()
2024-10-02 11:58:06,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171e32770>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x1721602b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:58:06,561:INFO:Checking exceptions
2024-10-02 11:58:06,561:INFO:Importing libraries
2024-10-02 11:58:06,561:INFO:Copying training dataset
2024-10-02 11:58:06,563:INFO:Defining folds
2024-10-02 11:58:06,563:INFO:Declaring metric variables
2024-10-02 11:58:06,563:INFO:Importing untrained model
2024-10-02 11:58:06,563:INFO:Dummy Classifier Imported successfully
2024-10-02 11:58:06,563:INFO:Starting cross validation
2024-10-02 11:58:06,564:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-10-02 11:58:06,603:INFO:Calculating mean and std
2024-10-02 11:58:06,603:INFO:Creating metrics dataframe
2024-10-02 11:58:06,604:INFO:Uploading results into container
2024-10-02 11:58:06,604:INFO:Uploading model into container now
2024-10-02 11:58:06,604:INFO:_master_model_container: 14
2024-10-02 11:58:06,604:INFO:_display_container: 2
2024-10-02 11:58:06,604:INFO:DummyClassifier(constant=None, random_state=8220, strategy='prior')
2024-10-02 11:58:06,604:INFO:create_model() successfully completed......................................
2024-10-02 11:58:06,640:INFO:SubProcess create_model() end ==================================
2024-10-02 11:58:06,640:INFO:Creating metrics dataframe
2024-10-02 11:58:06,642:WARNING:/Users/pratek/test1/Report/.venv/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-10-02 11:58:06,642:INFO:Initializing create_model()
2024-10-02 11:58:06,642:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x171e32770>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8220, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-10-02 11:58:06,642:INFO:Checking exceptions
2024-10-02 11:58:06,643:INFO:Importing libraries
2024-10-02 11:58:06,643:INFO:Copying training dataset
2024-10-02 11:58:06,644:INFO:Defining folds
2024-10-02 11:58:06,644:INFO:Declaring metric variables
2024-10-02 11:58:06,644:INFO:Importing untrained model
2024-10-02 11:58:06,644:INFO:Declaring custom model
2024-10-02 11:58:06,645:INFO:Extra Trees Classifier Imported successfully
2024-10-02 11:58:06,645:INFO:Cross validation set to False
2024-10-02 11:58:06,645:INFO:Fitting Model
2024-10-02 11:58:06,695:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8220, verbose=0,
                     warm_start=False)
2024-10-02 11:58:06,695:INFO:create_model() successfully completed......................................
2024-10-02 11:58:06,740:INFO:_master_model_container: 14
2024-10-02 11:58:06,740:INFO:_display_container: 2
2024-10-02 11:58:06,740:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8220, verbose=0,
                     warm_start=False)
2024-10-02 11:58:06,740:INFO:compare_models() successfully completed......................................
2024-10-02 11:58:06,744:INFO:Initializing save_model()
2024-10-02 11:58:06,744:INFO:save_model(model=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8220, verbose=0,
                     warm_start=False), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/tx/71pw4d8d2l95h2ffhyf9cq340000gn/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'sex', 'cp', 'trestbps',
                                             'chol', 'fbs', 'restecg',
                                             'thalach', 'exang', 'oldpeak',
                                             'slope', 'ca', 'thal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-10-02 11:58:06,744:INFO:Adding model into prep_pipe
2024-10-02 11:58:06,782:INFO:best_model.pkl saved in current working directory
2024-10-02 11:58:06,784:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['age', 'sex', 'cp', 'trestbps',
                                             'chol', 'fbs', 'restecg',
                                             'thalach', 'exang', 'oldpeak',
                                             'slope', 'ca', 'thal'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categ...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      monotonic_cst=None, n_estimators=100,
                                      n_jobs=-1, oob_score=False,
                                      random_state=8220, verbose=0,
                                      warm_start=False))],
         verbose=False)
2024-10-02 11:58:06,784:INFO:save_model() successfully completed......................................
